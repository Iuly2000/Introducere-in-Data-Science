{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modele de clasificare\n",
    "Folositi 4 seturi de date pentru probleme de clasificare, plecand de la repository-urile specificate in Cursul 6. Cel putin un set de date sa fie cu valori lipsa; pentru un alt set de date care are initial toate valorile, introduceti dvs. in mod artificial valori lipsa, suprascriind un anumit procent din valorile initiale (ex. p=5%, p parametru) cu numpy.nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 1.19.2\n",
      "Pandas version: 1.2.3\n",
      "Sklearn version: 0.24.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(f'NumPy version: {np.__version__}')\n",
    "\n",
    "import pandas as pd\n",
    "print(f'Pandas version: {pd.__version__}')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn as sk\n",
    "print(f'Sklearn version: {sk.__version__}')\n",
    "\n",
    "#NumPy version: 1.20.1\n",
    "#Pandas version: 1.2.3\n",
    "#Sklearn version: 0.24.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris: pd.core.frame.DataFrame = pd.read_csv(\"Data/iris.data\", header=None)\n",
    "x_iris: np.array = iris.iloc[:, :-1].values\n",
    "y_iris: np.array = iris[[4]].apply(le.fit_transform).values\n",
    "y_iris = y_iris.reshape(y_iris.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine:pd.core.frame.DataFrame = pd.read_csv(\"Data/wine.data\", header=None)\n",
    "x_wine: np.array = wine.iloc[:, 1:].values\n",
    "y_wine: np.array = wine.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdbc: pd.core.frame.DataFrame = pd.read_csv(\"Data/wdbc.data\", header=None)  \n",
    "x_wdbc: np.array = wdbc.iloc[:, 2:].values\n",
    "y_wdbc: np.array = wdbc[[1]].apply(le.fit_transform).values\n",
    "y_wdbc = y_wdbc.reshape(y_wdbc.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone: pd.core.frame.DataFrame = pd.read_csv(\"Data/abalone.data\", header=None) \n",
    "x_abalone: np.array = abalone.iloc[:, 1:].values\n",
    "y_abalone: np.array = abalone[[0]].apply(le.fit_transform).values\n",
    "y_abalone = y_abalone.reshape(y_abalone.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. (20 puncte) Aplicati o metoda de missing value imputation, unde este cazul; documentati metoda folosita.\n",
    "*Resurse*: Pentru missing value imputation, puteti urmari [Imputation of missing values](https://scikit-learn.org/stable/modules/impute.html), [How to Handle Missing Data with Python](https://machinelearningmastery.com/handle-missing-data-python/), [fancyimpute](https://github.com/iskandr/fancyimpute), [missingpy](https://github.com/epsilon-machine/missingpy).\n",
    "\n",
    "*Cerinta*: In cazul in care folositi un pachet ce trebuie instalat (nu face parte din distributia standard anaconda), includeti intr-o celula o comanda de instalare corespunzatoare folosind semn de exclamare, de exemplu:\n",
    "```python\n",
    "!pip install missingpy\n",
    "```\n",
    "(sursa: [https://github.com/epsilon-machine/missingpy](https://github.com/epsilon-machine/missingpy)). La executia celulei in Jupyter Notebook se instaleaza pachetul, iar in celulele ulterioare importurile din noul pachet functioneaza. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_Nans(data_set: np.array, percentage: int = 5) -> np.array:\n",
    "    \"\"\"\n",
    "    Adding NaN values in a dataset.\n",
    "    \n",
    "    Args:\n",
    "        data_set:the numpy.ndarray containing the dataset\n",
    "        percentage:the percentage(from dataset size) of Nans values to be added in the dataset\n",
    "        \n",
    "    Returns:\n",
    "        the modified dataset\n",
    "    \"\"\"\n",
    "    result_set: np.array = data_set.copy()\n",
    "    choice: np.array = np.random.choice(result_set.size, int(percentage / 100 * result_set.size), replace=False)\n",
    "    rows, cols = np.unravel_index(choice, result_set.shape)   \n",
    "    result_set[rows, cols] = np.nan\n",
    "    return result_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_iris = Random_Nans(x_iris)\n",
    "x_wine = Random_Nans(x_wine)\n",
    "x_wdbc = Random_Nans(x_wdbc)\n",
    "x_abalone = Random_Nans(x_abalone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer(missing_values = np.nan, strategy=\"most_frequent\")\n",
    "x_iris = imp.fit_transform(x_iris)\n",
    "x_wine = imp.fit_transform(x_wine)\n",
    "x_wdbc = imp.fit_transform(x_wdbc)\n",
    "x_abalone = imp.fit_transform(x_abalone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. (numar de modele * numar de seturi de date \\* 1 punct = 20 de puncte) Pentru fiecare set de date aplicati 5 modele de clasificare din scikit learn. Pentru fiecare raportati: acuratete, precision, recall, scorul F1 - a se vedea [sklearn.metrics](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics), [Precision and recall](https://en.wikipedia.org/wiki/Precision_and_recall) - folosind 5 fold cross validation. Raportati mediile rezultatelor atat pentru fold-urile de antrenare, cat si pentru cele de testare. Rularile se vor face cu valori fixate ale hiperparametrilor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    " x_iris_train, x_iris_test, y_iris_train, y_iris_test =train_test_split(\n",
    "    x_iris, y_iris, test_size=1/3, random_state=20, shuffle=True)\n",
    "\n",
    "x_wine_train, x_wine_test, y_wine_train, y_wine_test = train_test_split(\n",
    "    x_wine, y_wine, test_size=1/3, random_state=20, shuffle=True)\n",
    "\n",
    "x_wdbc_train, x_wdbc_test, y_wdbc_train, y_wdbc_test = train_test_split(\n",
    "    x_wdbc, y_wdbc, test_size=1/3, random_state=20, shuffle=True)\n",
    "\n",
    "x_abalone_train, x_abalone_test, y_abalone_train, y_abalone_test = train_test_split(\n",
    "    x_abalone, y_abalone, test_size=1/3, random_state=20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNeighbours(x, y, n_neighbors=5):\n",
    "    model_5 = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    model_5.fit(x, y)\n",
    "    y_pred = model_5.predict(x)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighbours: 97.0% accuracy for iris_train\n",
      "KNeighbours: 79.66% accuracy for wine_train\n",
      "KNeighbours: 94.99% accuracy for wdbc_train\n",
      "KNeighbours: 66.85% accuracy for abalone_train\n"
     ]
    }
   ],
   "source": [
    "print(f'KNeighbours: {round(accuracy_score(y_iris_train, KNeighbours(x_iris_train, y_iris_train)) * 100, 2)}% accuracy for iris_train')\n",
    "print(f'KNeighbours: {round(accuracy_score(y_wine_train, KNeighbours(x_wine_train, y_wine_train)) * 100, 2)}% accuracy for wine_train')\n",
    "print(f'KNeighbours: {round(accuracy_score(y_wdbc_train, KNeighbours(x_wdbc_train, y_wdbc_train)) * 100, 2)}% accuracy for wdbc_train')\n",
    "print(f'KNeighbours: {round(accuracy_score(y_abalone_train, KNeighbours(x_abalone_train, y_abalone_train)) * 100, 2)}% accuracy for abalone_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighbours: 94.0 % accuracy for iris_test\n",
      "KNeighbours: 78.33 % accuracy for wine_test\n",
      "KNeighbours: 92.63 % accuracy for wdbc_test\n",
      "KNeighbours: 66.4 % accuracy for abalone_test\n"
     ]
    }
   ],
   "source": [
    "print(f'KNeighbours: {round(accuracy_score(y_iris_test, KNeighbours(x_iris_test, y_iris_test)) * 100, 2)} % accuracy for iris_test')\n",
    "print(f'KNeighbours: {round(accuracy_score(y_wine_test, KNeighbours(x_wine_test, y_wine_test)) * 100, 2)} % accuracy for wine_test')\n",
    "print(f'KNeighbours: {round(accuracy_score(y_wdbc_test, KNeighbours(x_wdbc_test, y_wdbc_test)) * 100, 2)} % accuracy for wdbc_test')\n",
    "print(f'KNeighbours: {round(accuracy_score(y_abalone_test, KNeighbours(x_abalone_test, y_abalone_test)) * 100, 2)} % accuracy for abalone_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighbours: [100.          93.93939394  97.05882353] precision for iris_train\n",
      "KNeighbours: [82.60869565 79.54545455 75.        ] precision for wine_train\n",
      "KNeighbours: [94.35483871 96.18320611] precision for wdbc_train\n",
      "KNeighbours: [60.06864989 73.26732673 66.22222222] precision for abalone_train\n"
     ]
    }
   ],
   "source": [
    "print(f'KNeighbours: {precision_score(y_iris_train, KNeighbours(x_iris_train, y_iris_train, 5), average=None) * 100} precision for iris_train')\n",
    "print(f'KNeighbours: {precision_score(y_wine_train, KNeighbours(x_wine_train, y_wine_train, 5), average=None) * 100} precision for wine_train')\n",
    "print(f'KNeighbours: {precision_score(y_wdbc_train, KNeighbours(x_wdbc_train, y_wdbc_train, 5), average=None) * 100} precision for wdbc_train')\n",
    "print(f'KNeighbours: {precision_score(y_abalone_train, KNeighbours(x_abalone_train, y_abalone_train, 5), average=None) * 100} precision for abalone_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LRegression(x,y):\n",
    "    logreg = LogisticRegression(solver='sag', multi_class='multinomial', max_iter=10000)\n",
    "    logreg.fit(x, y)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
