{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modele de clasificare\n",
    "Folositi 4 seturi de date pentru probleme de clasificare, plecand de la repository-urile specificate in Cursul 6. Cel putin un set de date sa fie cu valori lipsa; pentru un alt set de date care are initial toate valorile, introduceti dvs. in mod artificial valori lipsa, suprascriind un anumit procent din valorile initiale (ex. p=5%, p parametru) cu numpy.nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 1.19.2\n",
      "Pandas version: 1.2.3\n",
      "Sklearn version: 0.24.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(f'NumPy version: {np.__version__}')\n",
    "\n",
    "import pandas as pd\n",
    "print(f'Pandas version: {pd.__version__}')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn as sk\n",
    "print(f'Sklearn version: {sk.__version__}')\n",
    "\n",
    "#NumPy version: 1.20.1\n",
    "#Pandas version: 1.2.3\n",
    "#Sklearn version: 0.24.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris: pd.core.frame.DataFrame = pd.read_csv(\"Data/iris.data\", header=None)\n",
    "x_iris: np.array = iris.iloc[:, :-1].values\n",
    "y_iris: np.array = iris[[4]].apply(le.fit_transform).values\n",
    "y_iris = y_iris.reshape(y_iris.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine:pd.core.frame.DataFrame = pd.read_csv(\"Data/wine.data\", header=None)\n",
    "x_wine: np.array = wine.iloc[:, 1:].values\n",
    "y_wine: np.array = wine.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdbc: pd.core.frame.DataFrame = pd.read_csv(\"Data/wdbc.data\", header=None)  \n",
    "x_wdbc: np.array = wdbc.iloc[:, 2:].values\n",
    "y_wdbc: np.array = wdbc[[1]].apply(le.fit_transform).values\n",
    "y_wdbc = y_wdbc.reshape(y_wdbc.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone: pd.core.frame.DataFrame = pd.read_csv(\"Data/abalone.data\", header=None) \n",
    "x_abalone: np.array = abalone.iloc[:, 1:].values\n",
    "y_abalone: np.array = abalone[[0]].apply(le.fit_transform).values\n",
    "y_abalone = y_abalone.reshape(y_abalone.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. (20 puncte) Aplicati o metoda de missing value imputation, unde este cazul; documentati metoda folosita.\n",
    "*Resurse*: Pentru missing value imputation, puteti urmari [Imputation of missing values](https://scikit-learn.org/stable/modules/impute.html), [How to Handle Missing Data with Python](https://machinelearningmastery.com/handle-missing-data-python/), [fancyimpute](https://github.com/iskandr/fancyimpute), [missingpy](https://github.com/epsilon-machine/missingpy).\n",
    "\n",
    "*Cerinta*: In cazul in care folositi un pachet ce trebuie instalat (nu face parte din distributia standard anaconda), includeti intr-o celula o comanda de instalare corespunzatoare folosind semn de exclamare, de exemplu:\n",
    "```python\n",
    "!pip install missingpy\n",
    "```\n",
    "(sursa: [https://github.com/epsilon-machine/missingpy](https://github.com/epsilon-machine/missingpy)). La executia celulei in Jupyter Notebook se instaleaza pachetul, iar in celulele ulterioare importurile din noul pachet functioneaza. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_nans(data_set: np.array, percentage: int = 5) -> np.array:\n",
    "    \"\"\"\n",
    "    Adding NaN values in a dataset.\n",
    "    \n",
    "    Args:\n",
    "        data_set:the numpy.ndarray containing the dataset\n",
    "        percentage:the percentage(from dataset size) of Nans values to be added in the dataset\n",
    "        \n",
    "    Returns:\n",
    "        the modified dataset\n",
    "    \"\"\"\n",
    "    result_set: np.array = data_set.copy()\n",
    "    choice: np.array = np.random.choice(result_set.size, int(percentage / 100 * result_set.size), replace=False)\n",
    "    rows, cols = np.unravel_index(choice, result_set.shape)   \n",
    "    result_set[rows, cols] = np.nan\n",
    "    return result_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_iris = random_nans(x_iris)\n",
    "x_wine = random_nans(x_wine)\n",
    "x_wdbc = random_nans(x_wdbc)\n",
    "x_abalone = random_nans(x_abalone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer(missing_values = np.nan, strategy=\"most_frequent\")\n",
    "x_iris = imp.fit_transform(x_iris)\n",
    "x_wine = imp.fit_transform(x_wine)\n",
    "x_wdbc = imp.fit_transform(x_wdbc)\n",
    "x_abalone = imp.fit_transform(x_abalone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. (numar de modele * numar de seturi de date \\* 1 punct = 20 de puncte) Pentru fiecare set de date aplicati 5 modele de clasificare din scikit learn. Pentru fiecare raportati: acuratete, precision, recall, scorul F1 - a se vedea [sklearn.metrics](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics), [Precision and recall](https://en.wikipedia.org/wiki/Precision_and_recall) - folosind 5 fold cross validation. Raportati mediile rezultatelor atat pentru fold-urile de antrenare, cat si pentru cele de testare. Rularile se vor face cu valori fixate ale hiperparametrilor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metrics_classifier(clf,x,y):\n",
    "    scoring=['recall_macro','precision_macro','accuracy','f1_macro']\n",
    "    scores = cross_validate(clf,x, y, cv=5,scoring=scoring,return_train_score=True)\n",
    "    df = pd.DataFrame(data={'train_accuracy': scores['train_accuracy'],\n",
    "                            'train_recall': scores['train_recall_macro'],\n",
    "                            'train_precision': scores['train_precision_macro'],\n",
    "                            'train_f1': scores['train_f1_macro'],\n",
    "                            'test_accuracy': scores['test_accuracy'],\n",
    "                            'test_recall': scores['test_recall_macro'],\n",
    "                            'test_precision': scores['test_precision_macro'],\n",
    "                            'test_f1': scores['test_f1_macro']\n",
    "                           })\n",
    "    df.loc['mean'] = df.mean()\n",
    "    with pd.option_context('expand_frame_repr', False):\n",
    "        print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for KNeighborsClassifier:\n",
      "\n",
      "Iris_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.941667      0.941667         0.943595  0.940678       0.966667     0.966667        0.969697  0.966583\n",
      "1           0.941667      0.941667         0.943595  0.940678       0.966667     0.966667        0.969697  0.966583\n",
      "2           0.958333      0.958333         0.958486  0.958115       0.900000     0.900000        0.923077  0.897698\n",
      "3           0.958333      0.958333         0.958516  0.958327       0.900000     0.900000        0.914141  0.895000\n",
      "4           0.933333      0.933333         0.933862  0.932392       1.000000     1.000000        1.000000  1.000000\n",
      "mean        0.946667      0.946667         0.947611  0.946038       0.946667     0.946667        0.955322  0.945173\n",
      "\n",
      "Wine_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.774648      0.768633         0.764115  0.765716       0.638889     0.629365        0.620513  0.624198\n",
      "1           0.823944      0.813301         0.815841  0.812626       0.694444     0.696032        0.693813  0.685764\n",
      "2           0.809859      0.804965         0.805012  0.804912       0.638889     0.615873        0.603632  0.607663\n",
      "3           0.811189      0.808683         0.804395  0.805387       0.657143     0.623016        0.659649  0.628283\n",
      "4           0.776224      0.768620         0.769320  0.765579       0.685714     0.658586        0.643315  0.648298\n",
      "mean        0.799173      0.792840         0.791737  0.790844       0.663016     0.644574        0.644185  0.638841\n",
      "\n",
      "Wdbc_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.945055      0.938139         0.943739  0.940799       0.894737     0.869636        0.908137  0.883077\n",
      "1           0.945055      0.934508         0.947545  0.940333       0.929825     0.916148        0.934359  0.923822\n",
      "2           0.936264      0.926574         0.936631  0.931150       0.921053     0.902778        0.927518  0.912837\n",
      "3           0.934066      0.924819         0.933626  0.928868       0.929825     0.919643        0.928716  0.923822\n",
      "4           0.947368      0.940148         0.946876  0.943311       0.920354     0.917170        0.913289  0.915144\n",
      "mean        0.941562      0.932838         0.941683  0.936892       0.919159     0.905075        0.922404  0.911740\n",
      "\n",
      "Abalone_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.682430      0.685692         0.680445  0.681633       0.503589     0.513326        0.494299  0.493573\n",
      "1           0.671955      0.676509         0.674426  0.672213       0.532297     0.535226        0.533858  0.534233\n",
      "2           0.693896      0.697793         0.693305  0.693544       0.495808     0.500623        0.494343  0.496235\n",
      "3           0.677439      0.681751         0.677053  0.677403       0.528144     0.530403        0.528204  0.529003\n",
      "4           0.675643      0.679182         0.674163  0.674803       0.519760     0.523914        0.522398  0.522612\n",
      "mean        0.680273      0.684186         0.679879  0.679919       0.515920     0.520698        0.514620  0.515131\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics for KNeighborsClassifier:\")\n",
    "print(\"\\nIris_Dataset:\")\n",
    "show_metrics_classifier(KNeighborsClassifier(n_neighbors=5),x_iris,y_iris) \n",
    "print(\"\\nWine_Dataset:\")\n",
    "show_metrics_classifier(KNeighborsClassifier(n_neighbors=5),x_wine ,y_wine )\n",
    "print(\"\\nWdbc_Dataset:\")\n",
    "show_metrics_classifier(KNeighborsClassifier(n_neighbors=5),x_wdbc ,y_wdbc )\n",
    "print(\"\\nAbalone_Dataset:\")\n",
    "show_metrics_classifier(KNeighborsClassifier(n_neighbors=5),x_abalone ,y_abalone )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for LogisticRegression:\n",
      "\n",
      "Iris_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.925000      0.925000         0.924349  0.924577       0.800000     0.800000        0.825397  0.791667\n",
      "1           0.941667      0.941667         0.941806  0.941437       0.933333     0.933333        0.944444  0.932660\n",
      "2           0.916667      0.916667         0.916015  0.916243       0.900000     0.900000        0.902357  0.899749\n",
      "3           0.941667      0.941667         0.941229  0.941349       0.866667     0.866667        0.877778  0.865993\n",
      "4           0.908333      0.908333         0.908002  0.907882       1.000000     1.000000        1.000000  1.000000\n",
      "mean        0.926667      0.926667         0.926280  0.926298       0.900000     0.900000        0.909995  0.898014\n",
      "\n",
      "Wine_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.901408      0.900212         0.912310  0.905363       0.777778     0.786508        0.790741  0.783076\n",
      "1           0.908451      0.907739         0.919626  0.912600       0.833333     0.834127        0.840252  0.835940\n",
      "2           0.894366      0.894364         0.902496  0.897980       0.916667     0.915079        0.927778  0.920196\n",
      "3           0.895105      0.894019         0.905491  0.898700       0.971429     0.972222        0.977778  0.974013\n",
      "4           0.909091      0.907280         0.917987  0.911558       0.914286     0.902357        0.944444  0.916756\n",
      "mean        0.901684      0.900723         0.911582  0.905240       0.882698     0.882059        0.896199  0.885996\n",
      "\n",
      "Wdbc_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.912088      0.893760         0.917423  0.903323       0.824561     0.785784        0.839098  0.799930\n",
      "1           0.890110      0.867805         0.895495  0.878436       0.894737     0.874222        0.901018  0.884459\n",
      "2           0.892308      0.868937         0.900641  0.880687       0.903509     0.888889        0.902051  0.894684\n",
      "3           0.881319      0.857792         0.887080  0.868711       0.929825     0.909722        0.941239  0.922051\n",
      "4           0.901316      0.878383         0.911023  0.890552       0.876106     0.862508        0.870205  0.866023\n",
      "mean        0.895428      0.873335         0.902333  0.884342       0.885748     0.864225        0.890722  0.873429\n",
      "\n",
      "Abalone_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.570787      0.564940         0.569728  0.546594       0.491627     0.498851        0.474578  0.468106\n",
      "1           0.549536      0.546292         0.546156  0.531720       0.586124     0.576311        0.589716  0.549693\n",
      "2           0.563734      0.558890         0.562546  0.540861       0.519760     0.518153        0.513151  0.507022\n",
      "3           0.550269      0.547001         0.547011  0.533004       0.583234     0.575076        0.585186  0.556542\n",
      "4           0.550269      0.545501         0.546769  0.526752       0.553293     0.546489        0.560454  0.529541\n",
      "mean        0.556919      0.552525         0.554442  0.535786       0.546808     0.542976        0.544617  0.522181\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics for LogisticRegression:\")\n",
    "print(\"\\nIris_Dataset:\")\n",
    "show_metrics_classifier(LogisticRegression(solver='sag', multi_class='multinomial', max_iter=10000),x_iris,y_iris) \n",
    "print(\"\\nWine_Dataset:\")\n",
    "show_metrics_classifier(LogisticRegression(solver='sag', multi_class='multinomial', max_iter=10000),x_wine ,y_wine )\n",
    "print(\"\\nWdbc_Dataset:\")\n",
    "show_metrics_classifier(LogisticRegression(solver='sag', multi_class='multinomial', max_iter=10000),x_wdbc ,y_wdbc )\n",
    "print(\"\\nAbalone_Dataset:\")\n",
    "show_metrics_classifier(LogisticRegression(solver='sag', multi_class='multinomial', max_iter=10000),x_abalone ,y_abalone )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for GaussianNB:\n",
      "\n",
      "Iris_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.941667      0.941667         0.941839  0.941658       0.833333     0.833333        0.849817  0.829497\n",
      "1           0.941667      0.941667         0.941839  0.941658       0.933333     0.933333        0.944444  0.932660\n",
      "2           0.941667      0.941667         0.941839  0.941658       0.933333     0.933333        0.944444  0.932660\n",
      "3           0.950000      0.950000         0.950710  0.949969       0.866667     0.866667        0.875000  0.865320\n",
      "4           0.916667      0.916667         0.916667  0.916667       1.000000     1.000000        1.000000  1.000000\n",
      "mean        0.938333      0.938333         0.938579  0.938322       0.913333     0.913333        0.922741  0.912027\n",
      "\n",
      "Wine_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.978873      0.981212         0.977381  0.979019       0.916667     0.928571        0.918803  0.916364\n",
      "1           0.964789      0.966592         0.963909  0.965172       0.972222     0.976190        0.969697  0.971781\n",
      "2           0.992958      0.994152         0.991453  0.992721       0.916667     0.905556        0.930556  0.912963\n",
      "3           0.958042      0.960969         0.956133  0.957982       0.885714     0.888889        0.925926  0.891667\n",
      "4           0.972028      0.975198         0.970623  0.972601       0.971429     0.977778        0.966667  0.970962\n",
      "mean        0.973338      0.975625         0.971900  0.973499       0.932540     0.935397        0.942330  0.932747\n",
      "\n",
      "Wdbc_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.938462      0.926842         0.940965  0.933083       0.912281     0.906649        0.906649  0.906649\n",
      "1           0.942857      0.932760         0.944437  0.938029       0.921053     0.899934        0.934829  0.912837\n",
      "2           0.936264      0.924200         0.939287  0.930786       0.938596     0.926587        0.941026  0.932981\n",
      "3           0.936264      0.924200         0.939287  0.930786       0.956140     0.945437        0.960513  0.952129\n",
      "4           0.942982      0.934266         0.943311  0.938430       0.946903     0.943159        0.943159  0.943159\n",
      "mean        0.939366      0.928454         0.941458  0.934223       0.934995     0.924353        0.937235  0.929551\n",
      "\n",
      "Abalone_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.544148      0.551907         0.531072  0.536089       0.494019     0.507374        0.479264  0.458369\n",
      "1           0.516312      0.535028         0.503812  0.479655       0.546651     0.564967        0.538609  0.522527\n",
      "2           0.529025      0.549538         0.520503  0.484745       0.481437     0.500286        0.468545  0.443306\n",
      "3           0.514063      0.532528         0.492827  0.478881       0.547305     0.566096        0.539099  0.519548\n",
      "4           0.524237      0.539544         0.505535  0.502099       0.529341     0.545683        0.510731  0.507972\n",
      "mean        0.525557      0.541709         0.510750  0.496294       0.519751     0.536881        0.507249  0.490344\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics for GaussianNB:\")\n",
    "print(\"\\nIris_Dataset:\")\n",
    "show_metrics_classifier(GaussianNB(),x_iris,y_iris) \n",
    "print(\"\\nWine_Dataset:\")\n",
    "show_metrics_classifier(GaussianNB(),x_wine ,y_wine )\n",
    "print(\"\\nWdbc_Dataset:\")\n",
    "show_metrics_classifier(GaussianNB(),x_wdbc ,y_wdbc )\n",
    "print(\"\\nAbalone_Dataset:\")\n",
    "show_metrics_classifier(GaussianNB(),x_abalone ,y_abalone )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for RandomForestClassifier:\n",
      "\n",
      " Iris_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.983333      0.983333         0.984127  0.983323       0.966667     0.966667        0.969697  0.966583\n",
      "1           0.983333      0.983333         0.983333  0.983333       0.900000     0.900000        0.923077  0.897698\n",
      "2           0.991667      0.991667         0.991870  0.991665       0.833333     0.833333        0.835017  0.832916\n",
      "3           1.000000      1.000000         1.000000  1.000000       0.866667     0.866667        0.866667  0.866667\n",
      "4           0.983333      0.983333         0.984127  0.983323       1.000000     1.000000        1.000000  1.000000\n",
      "mean        0.988333      0.988333         0.988691  0.988329       0.913333     0.913333        0.918891  0.912773\n",
      "\n",
      " Wine_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           1.000000      1.000000         1.000000  1.000000       0.916667     0.919048        0.915385  0.916296\n",
      "1           1.000000      1.000000         1.000000  1.000000       0.972222     0.976190        0.974359  0.974321\n",
      "2           0.992958      0.994152         0.991453  0.992721       0.888889     0.887302        0.904167  0.891919\n",
      "3           0.993007      0.994152         0.991667  0.992831       0.971429     0.976190        0.974359  0.974321\n",
      "4           1.000000      1.000000         1.000000  1.000000       0.942857     0.955556        0.938889  0.944154\n",
      "mean        0.997193      0.997661         0.996624  0.997110       0.938413     0.942857        0.941432  0.940202\n",
      "\n",
      " Wdbc_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.989011      0.986417         0.990068  0.988189       0.921053     0.913691        0.917659  0.915590\n",
      "1           0.982418      0.977542         0.984946  0.981031       0.921053     0.909106        0.921959  0.914749\n",
      "2           0.984615      0.981785         0.985331  0.983506       0.964912     0.962302        0.962302  0.962302\n",
      "3           0.986813      0.984727         0.987079  0.985880       0.921053     0.912698        0.916973  0.914749\n",
      "4           0.973684      0.969478         0.974159  0.971726       0.946903     0.943159        0.943159  0.943159\n",
      "mean        0.983308      0.979990         0.984317  0.982067       0.934995     0.928191        0.932410  0.930110\n",
      "\n",
      " Abalone_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.601317      0.593999         0.613359  0.571811       0.478469     0.481720        0.454647  0.441592\n",
      "1           0.578869      0.574772         0.584070  0.562116       0.570574     0.563656        0.571482  0.552317\n",
      "2           0.592759      0.586251         0.602661  0.565740       0.504192     0.499309        0.502274  0.481609\n",
      "3           0.582585      0.578248         0.587687  0.560231       0.577246     0.571536        0.572544  0.553781\n",
      "4           0.594554      0.585735         0.616908  0.557107       0.543713     0.533600        0.525513  0.493654\n",
      "mean        0.590017      0.583801         0.600937  0.563401       0.534839     0.529964        0.525292  0.504591\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics for RandomForestClassifier:\")\n",
    "print(\"\\n Iris_Dataset:\")\n",
    "show_metrics_classifier(RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1), x_iris, y_iris) \n",
    "print(\"\\n Wine_Dataset:\")\n",
    "show_metrics_classifier(RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1), x_wine ,y_wine )\n",
    "print(\"\\n Wdbc_Dataset:\")\n",
    "show_metrics_classifier(RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1), x_wdbc ,y_wdbc )\n",
    "print(\"\\n Abalone_Dataset:\")\n",
    "show_metrics_classifier(RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1), x_abalone ,y_abalone )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for DecisionTreeClassifier:\n",
      "\n",
      "Iris_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           1.000000      1.000000         1.000000  1.000000       0.966667     0.966667        0.969697  0.966583\n",
      "1           1.000000      1.000000         1.000000  1.000000       0.933333     0.933333        0.944444  0.932660\n",
      "2           1.000000      1.000000         1.000000  1.000000       0.900000     0.900000        0.902357  0.899749\n",
      "3           0.991667      0.991667         0.991870  0.991665       0.933333     0.933333        0.933333  0.933333\n",
      "4           1.000000      1.000000         1.000000  1.000000       0.966667     0.966667        0.969697  0.966583\n",
      "mean        0.998333      0.998333         0.998374  0.998333       0.940000     0.940000        0.943906  0.939782\n",
      "\n",
      "Wine_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0                1.0           1.0              1.0       1.0       0.805556     0.823810        0.819024  0.803313\n",
      "1                1.0           1.0              1.0       1.0       0.750000     0.724603        0.761111  0.716049\n",
      "2                1.0           1.0              1.0       1.0       0.777778     0.763492        0.798786  0.771136\n",
      "3                1.0           1.0              1.0       1.0       0.971429     0.972222        0.977778  0.974013\n",
      "4                1.0           1.0              1.0       1.0       0.914286     0.902357        0.912500  0.903282\n",
      "mean             1.0           1.0              1.0       1.0       0.843810     0.837297        0.853840  0.833559\n",
      "\n",
      "Wdbc_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.989011      0.987628         0.988821  0.988219       0.894737     0.892565        0.885990  0.888961\n",
      "1           0.991209      0.990586         0.990586  0.990586       0.929825     0.920734        0.929168  0.924603\n",
      "2           0.993407      0.993550         0.992391  0.992965       0.938596     0.941468        0.929952  0.934947\n",
      "3           0.995604      0.994118         0.996516  0.995293       0.912281     0.885913        0.929044  0.901316\n",
      "4           0.984649      0.981798         0.985361  0.983527       0.955752     0.959926        0.948203  0.953279\n",
      "mean        0.990776      0.989536         0.990735  0.990118       0.926238     0.920121        0.924471  0.920621\n",
      "\n",
      "Abalone_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.587848      0.579637         0.605054  0.567081       0.515550     0.515723        0.503537  0.495522\n",
      "1           0.567794      0.567667         0.556958  0.554521       0.571770     0.570182        0.553537  0.551439\n",
      "2           0.571514      0.563880         0.555827  0.534098       0.535329     0.529961        0.525159  0.511697\n",
      "3           0.577499      0.571425         0.584967  0.538347       0.548503     0.539811        0.518126  0.497851\n",
      "4           0.574207      0.565793         0.571583  0.545589       0.547305     0.536768        0.538947  0.511743\n",
      "mean        0.575772      0.569680         0.574878  0.547927       0.543692     0.538489        0.527861  0.513650\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics for DecisionTreeClassifier:\")\n",
    "print(\"\\nIris_Dataset:\")\n",
    "show_metrics_classifier(DecisionTreeClassifier(max_depth=5),x_iris,y_iris) \n",
    "print(\"\\nWine_Dataset:\")\n",
    "show_metrics_classifier(DecisionTreeClassifier(max_depth=5),x_wine ,y_wine )\n",
    "print(\"\\nWdbc_Dataset:\")\n",
    "show_metrics_classifier(DecisionTreeClassifier(max_depth=5),x_wdbc ,y_wdbc )\n",
    "print(\"\\nAbalone_Dataset:\")\n",
    "show_metrics_classifier(DecisionTreeClassifier(max_depth=5),x_abalone ,y_abalone )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. (numar de modele * numar de seturi de date * 1 punct = 20 de puncte) Raportati performanta fiecarui model, folosind 5 fold cross validation. Pentru fiecare din cele 5 rulari, cautati hiperparametrii optimi folosind 4-fold cross validation. Performanta modelului va fi raportata ca medie a celor  5 rulari. \n",
    "    *Observatie:* la fiecare din cele 5 rulari, hiperparametrii optimi pot diferi, din cauza datelor utilizate pentru antrenare/validare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metrics_classifier_with_performance(clf, parameter_grid, x, y):\n",
    "    show_metrics_classifier(GridSearchCV(estimator = clf, \n",
    "        param_grid=parameter_grid, cv=4, return_train_score=True), x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for KNeighborsClassifier with performance:\n",
      "\n",
      "Iris_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.916667      0.916667         0.920106  0.915948       0.933333     0.933333        0.933333  0.933333\n",
      "1           0.941667      0.941667         0.943595  0.940678       0.966667     0.966667        0.969697  0.966583\n",
      "2           1.000000      1.000000         1.000000  1.000000       0.900000     0.900000        0.902357  0.899749\n",
      "3           1.000000      1.000000         1.000000  1.000000       0.833333     0.833333        0.835017  0.832916\n",
      "4           0.941667      0.941667         0.941719  0.940991       1.000000     1.000000        1.000000  1.000000\n",
      "mean        0.960000      0.960000         0.961084  0.959523       0.926667     0.926667        0.928081  0.926516\n",
      "\n",
      "Wine_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.908451      0.904380         0.903203  0.903561       0.777778     0.786508        0.777001  0.775758\n",
      "1           1.000000      1.000000         1.000000  1.000000       0.722222     0.734921        0.726984  0.721057\n",
      "2           1.000000      1.000000         1.000000  1.000000       0.805556     0.796825        0.816667  0.803030\n",
      "3           1.000000      1.000000         1.000000  1.000000       0.771429     0.757937        0.805556  0.771008\n",
      "4           0.804196      0.800824         0.799498  0.798628       0.742857     0.709764        0.710227  0.709160\n",
      "mean        0.942529      0.941041         0.940540  0.940438       0.763968     0.757191        0.767287  0.756003\n",
      "\n",
      "Wdbc_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.938462      0.926842         0.940965  0.933083       0.885965     0.853423        0.911204  0.870850\n",
      "1           0.960440      0.952797         0.962363  0.957210       0.912281     0.902064        0.910124  0.905754\n",
      "2           0.942857      0.929463         0.948883  0.937692       0.921053     0.902778        0.927518  0.912837\n",
      "3           0.949451      0.941847         0.949775  0.945535       0.929825     0.919643        0.928716  0.923822\n",
      "4           0.949561      0.941896         0.949863  0.945604       0.929204     0.924212        0.924212  0.924212\n",
      "mean        0.948154      0.938569         0.950370  0.943825       0.915665     0.900424        0.920355  0.907495\n",
      "\n",
      "Abalone_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.640826      0.643231         0.637202  0.639334       0.495215     0.502432        0.482785  0.486019\n",
      "1           0.627656      0.632057         0.627359  0.628315       0.539474     0.542397        0.538265  0.540218\n",
      "2           0.662478      0.665384         0.659782  0.661700       0.481437     0.485110        0.479309  0.481927\n",
      "3           0.648115      0.651769         0.645752  0.647625       0.535329     0.536875        0.533488  0.535045\n",
      "4           0.635847      0.642135         0.635530  0.635207       0.532934     0.540164        0.533069  0.533407\n",
      "mean        0.642984      0.646915         0.641125  0.642436       0.516878     0.521395        0.513383  0.515323\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics for KNeighborsClassifier with performance:\")\n",
    "parameter_grid_KNeighborsClassifier = {'n_neighbors': list(range(1, 10)), 'p': [1, 2, 3, 10]}\n",
    "print(\"\\nIris_Dataset:\")\n",
    "show_metrics_classifier_with_performance(KNeighborsClassifier(), parameter_grid_KNeighborsClassifier, x_iris, y_iris) \n",
    "print(\"\\nWine_Dataset:\")\n",
    "show_metrics_classifier_with_performance(KNeighborsClassifier(), parameter_grid_KNeighborsClassifier, x_wine, y_wine )\n",
    "print(\"\\nWdbc_Dataset:\")\n",
    "show_metrics_classifier_with_performance(KNeighborsClassifier(), parameter_grid_KNeighborsClassifier, x_wdbc, y_wdbc )\n",
    "print(\"\\nAbalone_Dataset:\")\n",
    "show_metrics_classifier_with_performance(KNeighborsClassifier(), parameter_grid_KNeighborsClassifier, x_abalone, y_abalone )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Metrics for LogisticRegression with performance:\")\n",
    "parameter_grid_LogisticRegression = {}\n",
    "print(\"\\nIris_Dataset:\")\n",
    "show_metrics_classifier_with_performance(LogisticRegression(), parameter_grid_LogisticRegression, x_iris, y_iris) \n",
    "print(\"\\nWine_Dataset:\")\n",
    "show_metrics_classifier_with_performance(LogisticRegression(), parameter_grid_LogisticRegression, x_wine, y_wine )\n",
    "print(\"\\nWdbc_Dataset:\")\n",
    "show_metrics_classifier_with_performance(LogisticRegression(), parameter_grid_LogisticRegression, x_wdbc, y_wdbc )\n",
    "print(\"\\nAbalone_Dataset:\")\n",
    "show_metrics_classifier_with_performance(LogisticRegression(), parameter_grid_LogisticRegression, x_abalone, y_abalone )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Metrics for GaussianNB with performance:\")\n",
    "parameter_grid_GaussianNB = {}\n",
    "print(\"\\nIris_Dataset:\")\n",
    "show_metrics_classifier_with_performance(GaussianNB(), parameter_grid_GaussianNB, x_iris, y_iris) \n",
    "print(\"\\nWine_Dataset:\")\n",
    "show_metrics_classifier_with_performance(GaussianNB(), parameter_grid_GaussianNB, x_wine, y_wine )\n",
    "print(\"\\nWdbc_Dataset:\")\n",
    "show_metrics_classifier_with_performance(GaussianNB(), parameter_grid_GaussianNB, x_wdbc, y_wdbc )\n",
    "print(\"\\nAbalone_Dataset:\")\n",
    "show_metrics_classifier_with_performance(GaussianNB(), parameter_grid_GaussianNB, x_abalone, y_abalone )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Metrics for RandomForestClassifier with performance:\")\n",
    "parameter_grid_RandomForestClassifier = {}\n",
    "print(\"\\nIris_Dataset:\")\n",
    "show_metrics_classifier_with_performance(RandomForestClassifier(), parameter_grid_RandomForestClassifier, x_iris, y_iris) \n",
    "print(\"\\nWine_Dataset:\")\n",
    "show_metrics_classifier_with_performance(RandomForestClassifier(), parameter_grid_RandomForestClassifier, x_wine, y_wine )\n",
    "print(\"\\nWdbc_Dataset:\")\n",
    "show_metrics_classifier_with_performance(RandomForestClassifier(), parameter_grid_RandomForestClassifier, x_wdbc, y_wdbc )\n",
    "print(\"\\nAbalone_Dataset:\")\n",
    "show_metrics_classifier_with_performance(RandomForestClassifier(), parameter_grid_RandomForestClassifier, x_abalone, y_abalone )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Metrics for DecisionTreeClassifier with performance:\")\n",
    "parameter_grid_KNeighborsClassifier = {'n_neighbors': list(range(1, 10)), 'p': [1, 2, 3, 10]}\n",
    "print(\"\\nIris_Dataset:\")\n",
    "show_metrics_classifier_with_performance(DecisionTreeClassifier(), parameter_grid_KNeighborsClassifier, x_iris, y_iris) \n",
    "print(\"\\nWine_Dataset:\")\n",
    "show_metrics_classifier_with_performance(DecisionTreeClassifier(), parameter_grid_KNeighborsClassifier, x_wine, y_wine )\n",
    "print(\"\\nWdbc_Dataset:\")\n",
    "show_metrics_classifier_with_performance(DecisionTreeClassifier(), parameter_grid_KNeighborsClassifier, x_wdbc, y_wdbc )\n",
    "print(\"\\nAbalone_Dataset:\")\n",
    "show_metrics_classifier_with_performance(DecisionTreeClassifier(), parameter_grid_KNeighborsClassifier, x_abalone, y_abalone )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
