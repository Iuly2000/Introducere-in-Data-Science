{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modele de clasificare\n",
    "Folositi 4 seturi de date pentru probleme de clasificare, plecand de la repository-urile specificate in Cursul 6. Cel putin un set de date sa fie cu valori lipsa; pentru un alt set de date care are initial toate valorile, introduceti dvs. in mod artificial valori lipsa, suprascriind un anumit procent din valorile initiale (ex. p=5%, p parametru) cu numpy.nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 1.19.2\n",
      "Pandas version: 1.2.3\n",
      "Sklearn version: 0.24.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(f'NumPy version: {np.__version__}')\n",
    "\n",
    "import pandas as pd\n",
    "print(f'Pandas version: {pd.__version__}')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn as sk\n",
    "print(f'Sklearn version: {sk.__version__}')\n",
    "\n",
    "#NumPy version: 1.19.2\n",
    "#Pandas version: 1.2.3\n",
    "#Sklearn version: 0.24.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris: pd.core.frame.DataFrame = pd.read_csv(\"Data/iris.data\", header=None)\n",
    "x_iris: np.array = iris.iloc[:, :-1].values\n",
    "y_iris: np.array = iris[[4]].apply(le.fit_transform).values\n",
    "y_iris = y_iris.reshape(y_iris.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine:pd.core.frame.DataFrame = pd.read_csv(\"Data/wine.data\", header=None)\n",
    "x_wine: np.array = wine.iloc[:, 1:].values\n",
    "y_wine: np.array = wine.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdbc: pd.core.frame.DataFrame = pd.read_csv(\"Data/wdbc.data\", header=None)  \n",
    "x_wdbc: np.array = wdbc.iloc[:, 2:].values\n",
    "y_wdbc: np.array = wdbc[[1]].apply(le.fit_transform).values\n",
    "y_wdbc = y_wdbc.reshape(y_wdbc.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone: pd.core.frame.DataFrame = pd.read_csv(\"Data/abalone.data\", header=None) \n",
    "x_abalone: np.array = abalone.iloc[:, 1:].values\n",
    "y_abalone: np.array = abalone[[0]].apply(le.fit_transform).values\n",
    "y_abalone = y_abalone.reshape(y_abalone.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. (20 puncte) Aplicati o metoda de missing value imputation, unde este cazul; documentati metoda folosita.\n",
    "*Resurse*: Pentru missing value imputation, puteti urmari [Imputation of missing values](https://scikit-learn.org/stable/modules/impute.html), [How to Handle Missing Data with Python](https://machinelearningmastery.com/handle-missing-data-python/), [fancyimpute](https://github.com/iskandr/fancyimpute), [missingpy](https://github.com/epsilon-machine/missingpy).\n",
    "\n",
    "*Cerinta*: In cazul in care folositi un pachet ce trebuie instalat (nu face parte din distributia standard anaconda), includeti intr-o celula o comanda de instalare corespunzatoare folosind semn de exclamare, de exemplu:\n",
    "```python\n",
    "!pip install missingpy\n",
    "```\n",
    "(sursa: [https://github.com/epsilon-machine/missingpy](https://github.com/epsilon-machine/missingpy)). La executia celulei in Jupyter Notebook se instaleaza pachetul, iar in celulele ulterioare importurile din noul pachet functioneaza. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_nans(data_set: np.array, percentage: int = 5) -> np.array:\n",
    "    \"\"\"\n",
    "    Adding NaN values in a dataset.\n",
    "    \n",
    "    Args:\n",
    "        data_set: the numpy.ndarray containing the dataset\n",
    "        percentage: the percentage(from dataset size) of Nans values to be added in the dataset\n",
    "        \n",
    "    Returns:\n",
    "        the modified dataset\n",
    "    \"\"\"\n",
    "    result_set: np.array = data_set.copy()\n",
    "    choice: np.array = np.random.choice(result_set.size, int(percentage / 100 * result_set.size), replace=False)\n",
    "    rows, cols = np.unravel_index(choice, result_set.shape)   \n",
    "    result_set[rows, cols] = np.nan\n",
    "    return result_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_iris = random_nans(x_iris)\n",
    "x_wine = random_nans(x_wine)\n",
    "x_wdbc = random_nans(x_wdbc)\n",
    "x_abalone = random_nans(x_abalone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer(missing_values = np.nan, strategy=\"most_frequent\")\n",
    "x_iris = imp.fit_transform(x_iris)\n",
    "x_wine = imp.fit_transform(x_wine)\n",
    "x_wdbc = imp.fit_transform(x_wdbc)\n",
    "x_abalone = imp.fit_transform(x_abalone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. (numar de modele * numar de seturi de date \\* 1 punct = 20 de puncte) Pentru fiecare set de date aplicati 5 modele de clasificare din scikit learn. Pentru fiecare raportati: acuratete, precision, recall, scorul F1 - a se vedea [sklearn.metrics](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics), [Precision and recall](https://en.wikipedia.org/wiki/Precision_and_recall) - folosind 5 fold cross validation. Raportati mediile rezultatelor atat pentru fold-urile de antrenare, cat si pentru cele de testare. Rularile se vor face cu valori fixate ale hiperparametrilor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metrics_classifier(clf: sk.neighbors._classification.KNeighborsClassifier, x: np.array, y: np.array) -> None:\n",
    "    \"\"\"\n",
    "    Shows the metrics(accuracy, precision, f1, recall) of a classifier.\n",
    "    \n",
    "    Args:\n",
    "        clf: a classifier\n",
    "        x: np.array containning the dataset information\n",
    "        y: np.array containning the classification of the data\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    scoring = ['recall_macro', 'precision_macro', 'accuracy', 'f1_macro']\n",
    "    scores = cross_validate(clf, x, y, cv=5, scoring=scoring, return_train_score=True)\n",
    "    df = pd.DataFrame(data={'train_accuracy': scores['train_accuracy'],\n",
    "                            'train_recall': scores['train_recall_macro'],\n",
    "                            'train_precision': scores['train_precision_macro'],\n",
    "                            'train_f1': scores['train_f1_macro'],\n",
    "                            'test_accuracy': scores['test_accuracy'],\n",
    "                            'test_recall': scores['test_recall_macro'],\n",
    "                            'test_precision': scores['test_precision_macro'],\n",
    "                            'test_f1': scores['test_f1_macro']\n",
    "                           })\n",
    "    df.loc['mean'] = df.mean()\n",
    "    with pd.option_context('expand_frame_repr', False):\n",
    "        print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for KNeighborsClassifier:\n",
      "\n",
      "Iris_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.950000      0.950000         0.951058  0.949294       0.900000     0.900000        0.902357  0.899749\n",
      "1           0.933333      0.933333         0.933862  0.932392       1.000000     1.000000        1.000000  1.000000\n",
      "2           0.950000      0.950000         0.949916  0.949562       0.866667     0.866667        0.866667  0.866667\n",
      "3           0.933333      0.933333         0.933250  0.932896       0.866667     0.866667        0.875000  0.865320\n",
      "4           0.950000      0.950000         0.950000  0.950000       0.933333     0.933333        0.944444  0.932660\n",
      "mean        0.943333      0.943333         0.943617  0.942829       0.913333     0.913333        0.917694  0.912879\n",
      "\n",
      "Wine_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.802817      0.791589         0.791155  0.789905       0.750000     0.739683        0.744444  0.741178\n",
      "1           0.816901      0.798681         0.813807  0.799762       0.638889     0.623810        0.607089  0.598393\n",
      "2           0.809859      0.809568         0.805182  0.807013       0.666667     0.649206        0.648148  0.648014\n",
      "3           0.797203      0.782037         0.795299  0.780283       0.714286     0.687831        0.697421  0.688889\n",
      "4           0.755245      0.745574         0.747841  0.741256       0.800000     0.785185        0.776099  0.777496\n",
      "mean        0.796405      0.785490         0.790657  0.783644       0.713968     0.697143        0.694640  0.690794\n",
      "\n",
      "Wdbc_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.956044      0.946880         0.958939  0.952330       0.868421     0.834753        0.889482  0.850980\n",
      "1           0.949451      0.938004         0.953874  0.944957       0.912281     0.892892        0.921025  0.903716\n",
      "2           0.951648      0.942415         0.954131  0.947701       0.956140     0.950397        0.955062  0.952638\n",
      "3           0.947253      0.937719         0.949311  0.942947       0.956140     0.945437        0.960513  0.952129\n",
      "4           0.951754      0.942452         0.954223  0.947766       0.938053     0.936117        0.932060  0.934001\n",
      "mean        0.951230      0.941494         0.954096  0.947140       0.926207     0.911919        0.931628  0.918693\n",
      "\n",
      "Abalone_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.683029      0.686511         0.681019  0.682131       0.504785     0.515989        0.494354  0.489025\n",
      "1           0.670458      0.675235         0.671063  0.670194       0.526316     0.532328        0.524796  0.526593\n",
      "2           0.689408      0.693648         0.688108  0.688481       0.470659     0.477760        0.470613  0.470879\n",
      "3           0.672053      0.677002         0.672529  0.671759       0.540120     0.542416        0.541866  0.541939\n",
      "4           0.679234      0.682778         0.678458  0.679267       0.498204     0.504205        0.504207  0.502643\n",
      "mean        0.678836      0.683035         0.678235  0.678366       0.508017     0.514540        0.507167  0.506216\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics for KNeighborsClassifier:\")\n",
    "print(\"\\nIris_Dataset:\")\n",
    "show_metrics_classifier(KNeighborsClassifier(n_neighbors=5),x_iris,y_iris);\n",
    "print(\"\\nWine_Dataset:\")\n",
    "show_metrics_classifier(KNeighborsClassifier(n_neighbors=5),x_wine ,y_wine);\n",
    "print(\"\\nWdbc_Dataset:\")\n",
    "show_metrics_classifier(KNeighborsClassifier(n_neighbors=5),x_wdbc ,y_wdbc);\n",
    "print(\"\\nAbalone_Dataset:\")\n",
    "show_metrics_classifier(KNeighborsClassifier(n_neighbors=5),x_abalone ,y_abalone);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for LogisticRegression:\n",
      "\n",
      "Iris_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.941667      0.941667         0.941392  0.941237       0.833333     0.833333        0.828956  0.829741\n",
      "1           0.883333      0.883333         0.881495  0.882041       0.933333     0.933333        0.944444  0.932660\n",
      "2           0.891667      0.891667         0.892817  0.891044       0.933333     0.933333        0.944444  0.932660\n",
      "3           0.941667      0.941667         0.941806  0.941437       0.866667     0.866667        0.875000  0.865320\n",
      "4           0.900000      0.900000         0.900585  0.899937       0.900000     0.900000        0.907407  0.899522\n",
      "mean        0.911667      0.911667         0.911619  0.911139       0.893333     0.893333        0.900051  0.891980\n",
      "\n",
      "Wine_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.908451      0.904380         0.920295  0.910465       0.750000     0.758730        0.754762  0.753846\n",
      "1           0.901408      0.901891         0.907908  0.904509       0.805556     0.800794        0.818162  0.802469\n",
      "2           0.901408      0.898967         0.912459  0.904522       0.861111     0.859524        0.888235  0.868087\n",
      "3           0.909091      0.905715         0.920394  0.911477       0.942857     0.944444        0.958333  0.947475\n",
      "4           0.888112      0.887439         0.898188  0.891934       0.971429     0.969697        0.979167  0.973374\n",
      "mean        0.901694      0.899678         0.911849  0.904581       0.866190     0.866638        0.879732  0.869050\n",
      "\n",
      "Wdbc_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.909890      0.889591         0.917398  0.900467       0.877193     0.841795        0.905558  0.859951\n",
      "1           0.905495      0.881253         0.917857  0.894647       0.921053     0.904520        0.927632  0.913832\n",
      "2           0.905495      0.883024         0.915938  0.895297       0.912281     0.890873        0.920940  0.902564\n",
      "3           0.909890      0.888906         0.919188  0.900467       0.929825     0.909722        0.941239  0.922051\n",
      "4           0.912281      0.893089         0.919270  0.903437       0.902655     0.883635        0.906828  0.892965\n",
      "mean        0.908610      0.887173         0.917930  0.898863       0.908601     0.886109        0.920439  0.898273\n",
      "\n",
      "Abalone_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.556420      0.548528         0.553482  0.520769       0.502392     0.506102        0.491288  0.478126\n",
      "1           0.546244      0.541318         0.546677  0.522371       0.576555     0.565982        0.574825  0.535600\n",
      "2           0.558049      0.551733         0.557003  0.528435       0.505389     0.500983        0.495722  0.482077\n",
      "3           0.543986      0.539145         0.539432  0.519456       0.577246     0.569998        0.582352  0.554760\n",
      "4           0.544584      0.537979         0.540032  0.511153       0.549701     0.541030        0.560752  0.514884\n",
      "mean        0.549857      0.543741         0.547325  0.520437       0.542257     0.536819        0.540988  0.513089\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics for LogisticRegression:\")\n",
    "print(\"\\nIris_Dataset:\")\n",
    "show_metrics_classifier(LogisticRegression(solver='sag', multi_class='multinomial', max_iter=10000), x_iris,y_iris);\n",
    "print(\"\\nWine_Dataset:\")\n",
    "show_metrics_classifier(LogisticRegression(solver='sag', multi_class='multinomial', max_iter=10000), x_wine, y_wine);\n",
    "print(\"\\nWdbc_Dataset:\")\n",
    "show_metrics_classifier(LogisticRegression(solver='sag', multi_class='multinomial', max_iter=10000), x_wdbc, y_wdbc);\n",
    "print(\"\\nAbalone_Dataset:\")\n",
    "show_metrics_classifier(LogisticRegression(solver='sag', multi_class='multinomial', max_iter=10000) ,x_abalone, y_abalone);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for GaussianNB:\n",
      "\n",
      "Iris_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.941667      0.941667         0.941229  0.941349       0.800000     0.800000        0.805556  0.797980\n",
      "1           0.900000      0.900000         0.900569  0.899076       0.966667     0.966667        0.969697  0.966583\n",
      "2           0.900000      0.900000         0.899230  0.899335       0.900000     0.900000        0.923077  0.897698\n",
      "3           0.908333      0.908333         0.907468  0.907805       0.866667     0.866667        0.875000  0.865320\n",
      "4           0.916667      0.916667         0.916667  0.916667       0.933333     0.933333        0.939394  0.931217\n",
      "mean        0.913333      0.913333         0.913033  0.912846       0.893333     0.893333        0.902545  0.891760\n",
      "\n",
      "Wine_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.971831      0.975364         0.971503  0.973240       0.916667     0.928571        0.922078  0.918486\n",
      "1           0.985915      0.987060         0.985605  0.986239       0.944444     0.952381        0.944056  0.945153\n",
      "2           0.978873      0.981212         0.977381  0.979019       0.944444     0.948413        0.948413  0.948413\n",
      "3           0.979021      0.979968         0.980172  0.979839       0.914286     0.916667        0.941176  0.920123\n",
      "4           0.972028      0.975198         0.970623  0.972601       1.000000     1.000000        1.000000  1.000000\n",
      "mean        0.977534      0.979760         0.977057  0.978188       0.943968     0.949206        0.951145  0.946435\n",
      "\n",
      "Wdbc_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.936264      0.923884         0.939242  0.930598       0.929825     0.925319        0.925319  0.925319\n",
      "1           0.942857      0.932760         0.944437  0.938029       0.912281     0.892892        0.921025  0.903716\n",
      "2           0.936264      0.925387         0.937914  0.930970       0.947368     0.933532        0.953947  0.942230\n",
      "3           0.938462      0.927141         0.941014  0.933262       0.947368     0.938492        0.947973  0.942867\n",
      "4           0.936404      0.926635         0.936741  0.931236       0.955752     0.950201        0.954776  0.952397\n",
      "mean        0.938050      0.927161         0.939870  0.932819       0.938519     0.928087        0.940608  0.933306\n",
      "\n",
      "Abalone_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.547441      0.556141         0.534948  0.539234       0.501196     0.514285        0.490960  0.467412\n",
      "1           0.515115      0.533893         0.499392  0.478602       0.555024     0.573719        0.553551  0.530334\n",
      "2           0.530221      0.550487         0.522172  0.487931       0.483832     0.502465        0.468530  0.447205\n",
      "3           0.516457      0.534633         0.496455  0.483082       0.540120     0.558699        0.527121  0.513510\n",
      "4           0.519749      0.535621         0.498777  0.495897       0.531737     0.547481        0.514480  0.512747\n",
      "mean        0.525797      0.542155         0.510349  0.496949       0.522382     0.539330        0.510928  0.494242\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics for GaussianNB:\")\n",
    "print(\"\\nIris_Dataset:\")\n",
    "show_metrics_classifier(GaussianNB(), x_iris, y_iris);\n",
    "print(\"\\nWine_Dataset:\")\n",
    "show_metrics_classifier(GaussianNB(), x_wine, y_wine);\n",
    "print(\"\\nWdbc_Dataset:\")\n",
    "show_metrics_classifier(GaussianNB(), x_wdbc, y_wdbc);\n",
    "print(\"\\nAbalone_Dataset:\")\n",
    "show_metrics_classifier(GaussianNB(), x_abalone, y_abalone);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for RandomForestClassifier:\n",
      "\n",
      " Iris_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.983333      0.983333         0.984127  0.983323       0.900000     0.900000        0.902357  0.899749\n",
      "1           0.966667      0.966667         0.966667  0.966667       0.966667     0.966667        0.969697  0.966583\n",
      "2           0.991667      0.991667         0.991870  0.991665       0.900000     0.900000        0.902357  0.899749\n",
      "3           0.975000      0.975000         0.975997  0.974768       0.966667     0.966667        0.969697  0.966583\n",
      "4           0.991667      0.991667         0.991870  0.991665       0.966667     0.966667        0.969697  0.966583\n",
      "mean        0.981667      0.981667         0.982106  0.981618       0.940000     0.940000        0.942761  0.939850\n",
      "\n",
      " Wine_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           1.000000      1.000000         1.000000  1.000000       0.944444     0.942857        0.950549  0.945313\n",
      "1           1.000000      1.000000         1.000000  1.000000       0.916667     0.928571        0.922078  0.918486\n",
      "2           0.992958      0.994152         0.993056  0.993541       0.972222     0.966667        0.974359  0.969123\n",
      "3           0.993007      0.994152         0.991667  0.992831       1.000000     1.000000        1.000000  1.000000\n",
      "4           0.993007      0.994048         0.993197  0.993561       0.942857     0.940741        0.950000  0.943677\n",
      "mean        0.995794      0.996470         0.995584  0.995987       0.955238     0.955767        0.959397  0.955320\n",
      "\n",
      " Wdbc_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.982418      0.978752         0.983595  0.981080       0.912281     0.897478        0.914872  0.904778\n",
      "1           0.984615      0.981711         0.985325  0.983465       0.938596     0.923190        0.947368  0.932981\n",
      "2           0.973626      0.968266         0.975390  0.971619       0.947368     0.943452        0.943452  0.943452\n",
      "3           0.978022      0.975335         0.977642  0.976466       0.929825     0.914683        0.934211  0.922973\n",
      "4           0.975877      0.970033         0.978507  0.973984       0.938053     0.936117        0.932060  0.934001\n",
      "mean        0.978912      0.974819         0.980092  0.977323       0.933225     0.922984        0.934393  0.927637\n",
      "\n",
      " Abalone_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.600419      0.598723         0.598570  0.590564       0.489234     0.491868        0.469993  0.463615\n",
      "1           0.569291      0.564610         0.574931  0.547701       0.558612     0.549496        0.557864  0.528988\n",
      "2           0.597546      0.589798         0.618918  0.561750       0.505389     0.498850        0.498798  0.469778\n",
      "3           0.594255      0.591749         0.597798  0.580373       0.561677     0.558094        0.559596  0.549584\n",
      "4           0.586475      0.581447         0.590918  0.561067       0.555689     0.550061        0.562723  0.530965\n",
      "mean        0.589597      0.585266         0.596227  0.568291       0.534120     0.529674        0.529795  0.508586\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics for RandomForestClassifier:\")\n",
    "print(\"\\n Iris_Dataset:\")\n",
    "show_metrics_classifier(RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1), x_iris, y_iris);\n",
    "print(\"\\n Wine_Dataset:\")\n",
    "show_metrics_classifier(RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1), x_wine, y_wine);\n",
    "print(\"\\n Wdbc_Dataset:\")\n",
    "show_metrics_classifier(RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1), x_wdbc, y_wdbc);\n",
    "print(\"\\n Abalone_Dataset:\")\n",
    "show_metrics_classifier(RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1), x_abalone, y_abalone);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for DecisionTreeClassifier:\n",
      "\n",
      "Iris_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           1.000000      1.000000         1.000000  1.000000       0.933333     0.933333        0.944444  0.932660\n",
      "1           1.000000      1.000000         1.000000  1.000000       0.866667     0.866667        0.904762  0.868077\n",
      "2           1.000000      1.000000         1.000000  1.000000       0.900000     0.900000        0.902357  0.899749\n",
      "3           1.000000      1.000000         1.000000  1.000000       0.866667     0.866667        0.866667  0.866667\n",
      "4           0.991667      0.991667         0.991870  0.991665       0.966667     0.966667        0.969697  0.966583\n",
      "mean        0.998333      0.998333         0.998374  0.998333       0.906667     0.906667        0.917585  0.906747\n",
      "\n",
      "Wine_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           1.000000      1.000000         1.000000  1.000000       0.750000     0.776190        0.799397  0.736732\n",
      "1           1.000000      1.000000         1.000000  1.000000       0.777778     0.773016        0.771795  0.771605\n",
      "2           1.000000      1.000000         1.000000  1.000000       0.805556     0.796825        0.814744  0.801788\n",
      "3           0.993007      0.994152         0.993056  0.993541       0.885714     0.896825        0.891775  0.888745\n",
      "4           1.000000      1.000000         1.000000  1.000000       0.942857     0.940741        0.940741  0.940741\n",
      "mean        0.998601      0.998830         0.998611  0.998708       0.832381     0.836720        0.843690  0.827922\n",
      "\n",
      "Wdbc_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.991209      0.989376         0.991798  0.990563       0.894737     0.897150        0.885043  0.889855\n",
      "1           0.993407      0.992335         0.993539  0.992931       0.903509     0.890436        0.902703  0.895804\n",
      "2           0.991209      0.988235         0.993080  0.990563       0.929825     0.919643        0.928716  0.923822\n",
      "3           0.989011      0.985294         0.991379  0.988189       0.921053     0.902778        0.927518  0.912837\n",
      "4           0.989035      0.986487         0.990086  0.988234       0.955752     0.959926        0.948203  0.953279\n",
      "mean        0.990774      0.988345         0.991976  0.990096       0.920975     0.913987        0.918437  0.915119\n",
      "\n",
      "Abalone_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.589644      0.588212         0.582545  0.567663       0.496411     0.497127        0.488395  0.466998\n",
      "1           0.556420      0.564953         0.548359  0.543247       0.537081     0.544633        0.511597  0.515866\n",
      "2           0.573309      0.585325         0.566225  0.558859       0.510180     0.521325        0.500615  0.498828\n",
      "3           0.572711      0.577810         0.562226  0.563020       0.541317     0.548141        0.529043  0.535225\n",
      "4           0.578695      0.582558         0.568247  0.571312       0.549701     0.553830        0.544789  0.547732\n",
      "mean        0.574156      0.579771         0.565520  0.560820       0.526938     0.533011        0.514888  0.512930\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics for DecisionTreeClassifier:\")\n",
    "print(\"\\nIris_Dataset:\")\n",
    "show_metrics_classifier(DecisionTreeClassifier(max_depth=5), x_iris, y_iris);\n",
    "print(\"\\nWine_Dataset:\")\n",
    "show_metrics_classifier(DecisionTreeClassifier(max_depth=5), x_wine, y_wine);\n",
    "print(\"\\nWdbc_Dataset:\")\n",
    "show_metrics_classifier(DecisionTreeClassifier(max_depth=5), x_wdbc, y_wdbc);\n",
    "print(\"\\nAbalone_Dataset:\")\n",
    "show_metrics_classifier(DecisionTreeClassifier(max_depth=5), x_abalone, y_abalone);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. (numar de modele * numar de seturi de date * 1 punct = 20 de puncte) Raportati performanta fiecarui model, folosind 5 fold cross validation. Pentru fiecare din cele 5 rulari, cautati hiperparametrii optimi folosind 4-fold cross validation. Performanta modelului va fi raportata ca medie a celor  5 rulari. \n",
    "    *Observatie:* la fiecare din cele 5 rulari, hiperparametrii optimi pot diferi, din cauza datelor utilizate pentru antrenare/validare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metrics_classifier_with_performance(clf, parameter_grid: dict, x: np.array, y:np.array) -> None:\n",
    "    \"\"\"\n",
    "    Shows the metrics(accuracy,precision,f1,recall) of a classifier,by choosing the appropiate hiperparameters.\n",
    "    \n",
    "    Args:\n",
    "        clf: a classifier\n",
    "        parameter_grid: a dictionary containning the hiperparameters\n",
    "        x: np.array containning the dataset information\n",
    "        y: np.array containning the classification of the data\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    show_metrics_classifier(GridSearchCV(estimator = clf, \n",
    "        param_grid=parameter_grid, cv=4, return_train_score=True), x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for KNeighborsClassifier with performance:\n",
      "\n",
      "Iris_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.950000      0.950000         0.951058  0.949294       0.900000     0.900000        0.902357  0.899749\n",
      "1           1.000000      1.000000         1.000000  1.000000       0.966667     0.966667        0.969697  0.966583\n",
      "2           0.950000      0.950000         0.949916  0.949562       0.966667     0.966667        0.969697  0.966583\n",
      "3           0.933333      0.933333         0.936410  0.933106       0.866667     0.866667        0.881410  0.864904\n",
      "4           0.950000      0.950000         0.950710  0.949969       0.900000     0.900000        0.907407  0.899522\n",
      "mean        0.956667      0.956667         0.957619  0.956386       0.920000     0.920000        0.926114  0.919468\n",
      "\n",
      "Wine_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.866197      0.851313         0.870758  0.855003       0.666667     0.643651        0.638889  0.638889\n",
      "1           0.908451      0.902265         0.908317  0.903586       0.722222     0.729365        0.737584  0.716011\n",
      "2           1.000000      1.000000         1.000000  1.000000       0.666667     0.650794        0.678649  0.657194\n",
      "3           1.000000      1.000000         1.000000  1.000000       0.800000     0.794974        0.809259  0.798653\n",
      "4           1.000000      1.000000         1.000000  1.000000       0.914286     0.903704        0.908333  0.904461\n",
      "mean        0.954930      0.950715         0.955815  0.951718       0.753968     0.744497        0.754543  0.743042\n",
      "\n",
      "Wdbc_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.960440      0.950377         0.965278  0.956982       0.894737     0.865051        0.916947  0.881579\n",
      "1           0.962637      0.953335         0.966937  0.959426       0.938596     0.927776        0.941216  0.933693\n",
      "2           0.942857      0.928277         0.950538  0.937518       0.956140     0.945437        0.960513  0.952129\n",
      "3           0.940659      0.930083         0.942748  0.935731       0.947368     0.938492        0.947973  0.942867\n",
      "4           0.947368      0.937762         0.949409  0.943018       0.929204     0.924212        0.924212  0.924212\n",
      "mean        0.950792      0.939967         0.954982  0.946535       0.933209     0.920193        0.938172  0.926896\n",
      "\n",
      "Abalone_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.645016      0.648350         0.640424  0.643056       0.485646     0.493639        0.468921  0.472870\n",
      "1           0.630051      0.633959         0.628863  0.630183       0.521531     0.526241        0.517493  0.521484\n",
      "2           0.646020      0.652438         0.645515  0.644589       0.493413     0.501250        0.490972  0.491504\n",
      "3           0.654698      0.662231         0.657414  0.654586       0.522156     0.527099        0.532063  0.527930\n",
      "4           0.641831      0.647791         0.641278  0.640959       0.506587     0.511542        0.507049  0.508869\n",
      "mean        0.643523      0.648954         0.642699  0.642674       0.505867     0.511954        0.503299  0.504531\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics for KNeighborsClassifier with performance:\")\n",
    "parameter_grid_KNeighborsClassifier = {'n_neighbors': list(range(1, 10)), 'p': [1, 2, 3, 10]}\n",
    "print(\"\\nIris_Dataset:\")\n",
    "show_metrics_classifier_with_performance(KNeighborsClassifier(), parameter_grid_KNeighborsClassifier, x_iris, y_iris);\n",
    "print(\"\\nWine_Dataset:\")\n",
    "show_metrics_classifier_with_performance(KNeighborsClassifier(), parameter_grid_KNeighborsClassifier, x_wine, y_wine);\n",
    "print(\"\\nWdbc_Dataset:\")\n",
    "show_metrics_classifier_with_performance(KNeighborsClassifier(), parameter_grid_KNeighborsClassifier, x_wdbc, y_wdbc);\n",
    "print(\"\\nAbalone_Dataset:\")\n",
    "show_metrics_classifier_with_performance(KNeighborsClassifier(), parameter_grid_KNeighborsClassifier, x_abalone, y_abalone);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for LogisticRegression with performance:\n",
      "\n",
      "Iris_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.958333      0.958333         0.958516  0.958327       0.933333     0.933333        0.944444  0.932660\n",
      "1           0.925000      0.925000         0.925162  0.924988       0.966667     0.966667        0.969697  0.966583\n",
      "2           0.941667      0.941667         0.943222  0.941585       0.900000     0.900000        0.923077  0.897698\n",
      "3           0.933333      0.933333         0.933333  0.933333       0.833333     0.833333        0.849817  0.829497\n",
      "4           0.916667      0.916667         0.916667  0.916667       0.900000     0.900000        0.907407  0.899522\n",
      "mean        0.935000      0.935000         0.935380  0.934980       0.906667     0.906667        0.918889  0.905192\n",
      "\n",
      "Wine_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0                1.0           1.0              1.0       1.0       1.000000     1.000000        1.000000  1.000000\n",
      "1                1.0           1.0              1.0       1.0       0.944444     0.952381        0.944056  0.945153\n",
      "2                1.0           1.0              1.0       1.0       0.944444     0.948413        0.945887  0.945825\n",
      "3                1.0           1.0              1.0       1.0       1.000000     1.000000        1.000000  1.000000\n",
      "4                1.0           1.0              1.0       1.0       1.000000     1.000000        1.000000  1.000000\n",
      "mean             1.0           1.0              1.0       1.0       0.977778     0.980159        0.977989  0.978195\n",
      "\n",
      "Wdbc_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.980220      0.978214         0.979384  0.978793       0.973684     0.965116        0.979730  0.971583\n",
      "1           0.984615      0.981711         0.985325  0.983465       0.964912     0.962660        0.962660  0.962660\n",
      "2           0.978022      0.975335         0.977642  0.976466       0.973684     0.974206        0.969702  0.971863\n",
      "3           0.980220      0.978277         0.979424  0.978845       0.947368     0.943452        0.943452  0.943452\n",
      "4           0.975877      0.973612         0.974754  0.974177       0.964602     0.962106        0.962106  0.962106\n",
      "mean        0.979791      0.977430         0.979306  0.978349       0.964850     0.961508        0.963530  0.962333\n",
      "\n",
      "Abalone_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.560311      0.553531         0.554829  0.528695       0.502392     0.506026        0.489043  0.476905\n",
      "1           0.547441      0.545041         0.542983  0.532202       0.589713     0.582356        0.583088  0.562299\n",
      "2           0.569719      0.565117         0.568459  0.547391       0.513772     0.510929        0.509024  0.498167\n",
      "3           0.549372      0.546007         0.543683  0.529620       0.574850     0.568860        0.578614  0.556290\n",
      "4           0.547576      0.542452         0.542002  0.521109       0.558084     0.551644        0.564112  0.533355\n",
      "mean        0.554884      0.550430         0.550391  0.531803       0.547762     0.543963        0.544776  0.525403\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics for LogisticRegression with performance:\")\n",
    "parameter_grid_LogisticRegression = {'solver' : ['newton-cg', 'sag', 'saga'],\n",
    "                                     'penalty' : ['l2'],\n",
    "                                     'C' : [100, 10, 1.0, 0.1, 0.01],\n",
    "                                     'max_iter' : [10000]}\n",
    "print(\"\\nIris_Dataset:\")\n",
    "show_metrics_classifier_with_performance(LogisticRegression(), parameter_grid_LogisticRegression, x_iris, y_iris);\n",
    "print(\"\\nWine_Dataset:\")\n",
    "show_metrics_classifier_with_performance(LogisticRegression(), parameter_grid_LogisticRegression, x_wine, y_wine);\n",
    "print(\"\\nWdbc_Dataset:\")\n",
    "show_metrics_classifier_with_performance(LogisticRegression(), parameter_grid_LogisticRegression, x_wdbc, y_wdbc);\n",
    "print(\"\\nAbalone_Dataset:\")\n",
    "show_metrics_classifier_with_performance(LogisticRegression(), parameter_grid_LogisticRegression, x_abalone, y_abalone);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for GaussianNB with performance:\n",
      "\n",
      "Iris_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.941667      0.941667         0.941229  0.941349       0.800000     0.800000        0.805556  0.797980\n",
      "1           0.883333      0.883333         0.883598  0.882328       0.933333     0.933333        0.944444  0.932660\n",
      "2           0.900000      0.900000         0.898601  0.898921       0.900000     0.900000        0.923077  0.897698\n",
      "3           0.908333      0.908333         0.907468  0.907805       0.866667     0.866667        0.875000  0.865320\n",
      "4           0.908333      0.908333         0.908484  0.908319       0.933333     0.933333        0.939394  0.931217\n",
      "mean        0.908333      0.908333         0.907876  0.907744       0.886667     0.886667        0.897494  0.884975\n",
      "\n",
      "Wine_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.978873      0.981212         0.978408  0.979729       0.972222     0.976190        0.969697  0.971781\n",
      "1           0.992958      0.994152         0.991453  0.992721       0.861111     0.867460        0.867460  0.864103\n",
      "2           0.971831      0.975364         0.969549  0.971853       0.972222     0.972222        0.977778  0.974013\n",
      "3           0.944056      0.942841         0.948635  0.945331       0.942857     0.944444        0.958333  0.947475\n",
      "4           0.965035      0.965659         0.965789  0.965500       1.000000     1.000000        1.000000  1.000000\n",
      "mean        0.970551      0.971846         0.970767  0.971027       0.949683     0.952063        0.954654  0.951474\n",
      "\n",
      "Wdbc_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.936264      0.920253         0.943989  0.930011       0.885965     0.862594        0.894231  0.874097\n",
      "1           0.945055      0.934508         0.947545  0.940333       0.921053     0.899934        0.934829  0.912837\n",
      "2           0.940659      0.928896         0.944150  0.935560       0.938596     0.926587        0.941026  0.932981\n",
      "3           0.938462      0.927141         0.941014  0.933262       0.947368     0.938492        0.947973  0.942867\n",
      "4           0.938596      0.927190         0.941126  0.933344       0.964602     0.957243        0.966952  0.961721\n",
      "mean        0.939807      0.927598         0.943565  0.934502       0.931517     0.916970        0.937002  0.924900\n",
      "\n",
      "Abalone_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.552230      0.551259         0.539222  0.529475       0.472488     0.483488        0.454244  0.442285\n",
      "1           0.520204      0.533163         0.503134  0.500278       0.566986     0.577655        0.549977  0.553367\n",
      "2           0.536505      0.537987         0.521563  0.516609       0.512575     0.515758        0.501009  0.499995\n",
      "3           0.530221      0.542702         0.513936  0.511339       0.536527     0.548584        0.519910  0.524331\n",
      "4           0.535607      0.537905         0.522348  0.517411       0.529341     0.530282        0.514310  0.510610\n",
      "mean        0.534953      0.540603         0.520041  0.515022       0.523583     0.531154        0.507890  0.506117\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics for GaussianNB with performance:\")\n",
    "parameter_grid_GaussianNB = {'var_smoothing' : np.logspace(0, -9, num=100)}\n",
    "print(\"\\nIris_Dataset:\")\n",
    "show_metrics_classifier_with_performance(GaussianNB(), parameter_grid_GaussianNB, x_iris, y_iris);\n",
    "print(\"\\nWine_Dataset:\")\n",
    "show_metrics_classifier_with_performance(GaussianNB(), parameter_grid_GaussianNB, x_wine, y_wine);\n",
    "print(\"\\nWdbc_Dataset:\")\n",
    "show_metrics_classifier_with_performance(GaussianNB(), parameter_grid_GaussianNB, x_wdbc, y_wdbc);\n",
    "print(\"\\nAbalone_Dataset:\")\n",
    "show_metrics_classifier_with_performance(GaussianNB(), parameter_grid_GaussianNB, x_abalone, y_abalone);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for RandomForestClassifier with performance:\n",
      "\n",
      "Iris_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           1.000000      1.000000         1.000000  1.000000       0.933333     0.933333        0.944444  0.932660\n",
      "1           1.000000      1.000000         1.000000  1.000000       0.966667     0.966667        0.969697  0.966583\n",
      "2           0.991667      0.991667         0.991870  0.991665       0.933333     0.933333        0.944444  0.932660\n",
      "3           1.000000      1.000000         1.000000  1.000000       0.900000     0.900000        0.911111  0.899327\n",
      "4           1.000000      1.000000         1.000000  1.000000       0.966667     0.966667        0.969697  0.966583\n",
      "mean        0.998333      0.998333         0.998374  0.998333       0.940000     0.940000        0.947879  0.939563\n",
      "\n",
      "Wine_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0                1.0           1.0              1.0       1.0       0.888889     0.904762        0.903030  0.891534\n",
      "1                1.0           1.0              1.0       1.0       0.944444     0.952381        0.944056  0.945153\n",
      "2                1.0           1.0              1.0       1.0       1.000000     1.000000        1.000000  1.000000\n",
      "3                1.0           1.0              1.0       1.0       1.000000     1.000000        1.000000  1.000000\n",
      "4                1.0           1.0              1.0       1.0       0.971429     0.977778        0.972222  0.974013\n",
      "mean             1.0           1.0              1.0       1.0       0.960952     0.966984        0.963862  0.962140\n",
      "\n",
      "Wdbc_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0                1.0           1.0              1.0       1.0       0.929825     0.925319        0.925319  0.925319\n",
      "1                1.0           1.0              1.0       1.0       0.938596     0.923190        0.947368  0.932981\n",
      "2                1.0           1.0              1.0       1.0       0.982456     0.981151        0.981151  0.981151\n",
      "3                1.0           1.0              1.0       1.0       0.956140     0.945437        0.960513  0.952129\n",
      "4                1.0           1.0              1.0       1.0       0.982301     0.985915        0.977273  0.981229\n",
      "mean             1.0           1.0              1.0       1.0       0.957864     0.952202        0.958325  0.954562\n",
      "\n",
      "Abalone_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0                1.0           1.0              1.0       1.0       0.497608     0.502504        0.484182  0.485336\n",
      "1                1.0           1.0              1.0       1.0       0.563397     0.565680        0.557320  0.560439\n",
      "2                1.0           1.0              1.0       1.0       0.502994     0.505724        0.506249  0.505903\n",
      "3                1.0           1.0              1.0       1.0       0.562874     0.562085        0.560747  0.560420\n",
      "4                1.0           1.0              1.0       1.0       0.548503     0.550067        0.545726  0.547388\n",
      "mean             1.0           1.0              1.0       1.0       0.535075     0.537212        0.530845  0.531897\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics for RandomForestClassifier with performance:\")\n",
    "parameter_grid_RandomForestClassifier = {'n_estimators' : [10, 100, 1000], 'max_features' : ['sqrt', 'log2']}\n",
    "print(\"\\nIris_Dataset:\")\n",
    "show_metrics_classifier_with_performance(RandomForestClassifier(), parameter_grid_RandomForestClassifier, x_iris, y_iris);\n",
    "print(\"\\nWine_Dataset:\")\n",
    "show_metrics_classifier_with_performance(RandomForestClassifier(), parameter_grid_RandomForestClassifier, x_wine, y_wine);\n",
    "print(\"\\nWdbc_Dataset:\")\n",
    "show_metrics_classifier_with_performance(RandomForestClassifier(), parameter_grid_RandomForestClassifier, x_wdbc, y_wdbc);\n",
    "print(\"\\nAbalone_Dataset:\")\n",
    "show_metrics_classifier_with_performance(RandomForestClassifier(), parameter_grid_RandomForestClassifier, x_abalone, y_abalone);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for DecisionTreeClassifier with performance:\n",
      "\n",
      "Iris_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.950000      0.950000         0.951115  0.949850       0.933333     0.933333        0.944444  0.932660\n",
      "1           0.991667      0.991667         0.991870  0.991665       0.833333     0.833333        0.888889  0.837473\n",
      "2           0.950000      0.950000         0.953991  0.949853       0.900000     0.900000        0.902357  0.899749\n",
      "3           1.000000      1.000000         1.000000  1.000000       0.833333     0.833333        0.835017  0.832916\n",
      "4           1.000000      1.000000         1.000000  1.000000       0.966667     0.966667        0.969697  0.966583\n",
      "mean        0.978333      0.978333         0.979395  0.978274       0.893333     0.893333        0.908081  0.893876\n",
      "\n",
      "Wine_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           1.000000      1.000000         1.000000  1.000000       0.750000     0.776190        0.799397  0.736732\n",
      "1           1.000000      1.000000         1.000000  1.000000       0.805556     0.804762        0.796825  0.797436\n",
      "2           1.000000      1.000000         1.000000  1.000000       0.833333     0.820635        0.860577  0.830065\n",
      "3           0.986014      0.988304         0.986395  0.987103       0.885714     0.887566        0.887566  0.887566\n",
      "4           1.000000      1.000000         1.000000  1.000000       0.885714     0.880135        0.887963  0.883086\n",
      "mean        0.997203      0.997661         0.997279  0.997421       0.832063     0.833858        0.846466  0.826977\n",
      "\n",
      "Wdbc_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.962637      0.954545         0.965466  0.959534       0.921053     0.918277        0.914610  0.916361\n",
      "1           0.982418      0.976331         0.986395  0.980982       0.903509     0.876679        0.922794  0.892148\n",
      "2           0.982418      0.976471         0.986348  0.981031       0.938596     0.926587        0.941026  0.932981\n",
      "3           0.980220      0.977090         0.980601  0.978793       0.938596     0.926587        0.941026  0.932981\n",
      "4           1.000000      1.000000         1.000000  1.000000       0.982301     0.985915        0.977273  0.981229\n",
      "mean        0.981538      0.976887         0.983762  0.980068       0.936811     0.926809        0.939346  0.931140\n",
      "\n",
      "Abalone_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.574080      0.567229         0.565845  0.537770       0.497608     0.495855        0.483824  0.470327\n",
      "1           0.542951      0.543773         0.552923  0.547308       0.519139     0.516904        0.541995  0.523726\n",
      "2           0.599342      0.597922         0.593879  0.591362       0.523353     0.522297        0.522163  0.519954\n",
      "3           0.563734      0.568127         0.552248  0.553017       0.549701     0.556216        0.536809  0.542790\n",
      "4           0.562238      0.564979         0.558041  0.560402       0.542515     0.544887        0.548086  0.546029\n",
      "mean        0.568469      0.568406         0.564587  0.557972       0.526463     0.527232        0.526575  0.520565\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics for DecisionTreeClassifier with performance:\")\n",
    "parameter_grid_KNeighborsClassifier = {'criterion' : ['gini', 'entropy'], 'max_depth' : [2, 4, 6, 8, 10, 12]}\n",
    "print(\"\\nIris_Dataset:\")\n",
    "show_metrics_classifier_with_performance(DecisionTreeClassifier(), parameter_grid_KNeighborsClassifier, x_iris, y_iris);\n",
    "print(\"\\nWine_Dataset:\")\n",
    "show_metrics_classifier_with_performance(DecisionTreeClassifier(), parameter_grid_KNeighborsClassifier, x_wine, y_wine);\n",
    "print(\"\\nWdbc_Dataset:\")\n",
    "show_metrics_classifier_with_performance(DecisionTreeClassifier(), parameter_grid_KNeighborsClassifier, x_wdbc, y_wdbc);\n",
    "print(\"\\nAbalone_Dataset:\")\n",
    "show_metrics_classifier_with_performance(DecisionTreeClassifier(), parameter_grid_KNeighborsClassifier, x_abalone, y_abalone);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. (numar modele * 4 puncte = 20 puncte) Documentati in jupyter notebook fiecare din modelele folosite, in limba romana. Daca acelasi algoritm e folosit pentru mai multe seturi de date, puteti face o sectiune separata cu documentarea algoritmilor + trimitere la algoritm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. KNeighborsClassifier\n",
    "Clasificare K-nearest-neighbor (kNN) este una dintre cele mai fundamentale si simple metode de clasificare fiind printre primele alegeri pentru a invata o clasificare atunci cand nu se stie informatii despre distribuirea datelor. Aceasta metoda a fost dezvoltata din nevoia de a efectua o analiza discriminatoare cand probabilitatea parametrilor de densitate este necunoscuta sau dificil de determinat.Este folosit pentru clasificare si regresie, in ambele cazuri, inputul consista in k cele mai apropiate exemple de antrenare din dataset. Intr-o clasificare outputul este o clasa membru.\n",
    "\n",
    "In aceata metoda se folosesc k vecini, cei mai apropiati de inregistrarea ce se vrea a  clasicata.\n",
    "Metoda are nevoie de: setul de inregistrari cu clase cunoscute, o metrica (distanta, functie de similaritate) care calculeaza distanta intre doua inregistrari, pe baza valorilor atributelor valoarea k, numarul de vecini cei mai apropiati care sunt considerati.\n",
    "\n",
    "Pentru clasicarea unei inregistrari: se calculeaza distanta catre alte inregistrari din setul de antrenare, se identica cei mai apropiati k vecini, se folosesc etichetele de clasa ale acestor k vecini pentru a estima clasa asociata inregistrarii de test (de exemplu prin considerarea votului majoritar)\n",
    "\n",
    "class sklearn.neighbors.KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None, **kwargs)\n",
    "\n",
    "[KNeighborsClassifier documentatie](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. LogisticRegression\n",
    "Regresia logistica este o clasificare fundamentala. Apartine grupului liniar de clasificatori si este oarecum similar cu regresia polinomiala si liniara. Regresia logistica este rapida si relativ usoara de inteles, fiind usor de interpretat rezultatele. Regresia logistica este folosita pentru estimare de probabilitate conditionatasi clasificare. Initial dezvoltata pentru lucrul cu doua clase, a fost extinsa pentru a discrimina intre oricate clase  regresia logistica multinomiala.\n",
    "\n",
    "Ca mod de instruire se foloseste invatarea supervizata. Intrarile sunt vectori numerici, iar clasele sunt fie doua (pentru regresia logistica binara), fie mai multe (pentru regresia logistica multinomiala).\n",
    "\n",
    "class sklearn.linear_model.LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "\n",
    "[LogisticRegression documentatie](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logisticregression#sklearn.linear_model.LogisticRegression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. GaussianNB\n",
    "Algoritmul gaussion Naive Bayes este un algoritm NB special. Este utilizat atunci cand trasaturile au valori continue. De asemenea trebuie asumat faptul ca toate trasaturile urmeaza o distributie gausiana(normal distribution). Acest algoritm este bazat pe probabilitate conditionata. Probabilitatea conditionata ne ajuta sa calculam probabilitatea ca ceva se va intampla, avand in vedere ca altceva deja s-a intamplat.\n",
    "\n",
    "class sklearn.naive_bayes.GaussianNB(*, priors=None, var_smoothing=1e-09)\n",
    "\n",
    "[GaussianNB documentatie](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  4. Random forest\n",
    "Padurile aleatoare sunt o metoda de invatare pentru clasificare, regresie si alte sarcini care opereaza prin construirea unei multitudini de arbori de decizie pe mai multe subseturi de date si care foloseste o medie pentru a imbunatati precizia predictiva.\n",
    "\n",
    "class sklearn.ensemble.RandomForestClassifier(n_estimators=warn, criterion=gini, max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=auto, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None)\n",
    "\n",
    "[RandomForestClassifier_documentatie](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  5. DecisionTreeClassifier\n",
    "Arborii de decizie (DT) sunt o metoda de invatare neparametrica, supravegheata folosita pentru clasificare si regresie. Scopul lor este de a crea un model care prezice valoarea unei variabile tinta prin invatarea unor reguli simple de decizie deduse din caracteristicile datelor de antrenare. Astfel, fiecare nod intern al arborelui corespunde unui atribut, iar fiecare nod frunza corespunde unei etichete de clasa. Algoritmul plaseaza cel mai bun atribut al setului de date la radacina arborelui. Imparte setul de antrenare in subseturi. Subseturile sunt facute astfel incat fiecare subset sa contina date cu aceeasi valoare pentru un atribut. Se repeta pasii de mai sus pe fiecare subset pana cand se gasesc nodurile frunza pentru toate ramurile arborelui.\n",
    "\n",
    "class sklearn.tree.DecisionTreeClassifier(criterion=gini, splitter=best, max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort=False)\n",
    "\n",
    "[DecisionTreeClassifier_documentaie](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
