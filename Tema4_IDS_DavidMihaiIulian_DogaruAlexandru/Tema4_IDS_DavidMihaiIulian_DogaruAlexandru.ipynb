{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modele de clasificare\n",
    "Folositi 4 seturi de date pentru probleme de clasificare, plecand de la repository-urile specificate in Cursul 6. Cel putin un set de date sa fie cu valori lipsa; pentru un alt set de date care are initial toate valorile, introduceti dvs. in mod artificial valori lipsa, suprascriind un anumit procent din valorile initiale (ex. p=5%, p parametru) cu numpy.nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 1.19.2\n",
      "Pandas version: 1.2.3\n",
      "Sklearn version: 0.24.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(f'NumPy version: {np.__version__}')\n",
    "\n",
    "import pandas as pd\n",
    "print(f'Pandas version: {pd.__version__}')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import sklearn as sk\n",
    "print(f'Sklearn version: {sk.__version__}')\n",
    "\n",
    "#NumPy version: 1.20.1\n",
    "#Pandas version: 1.2.3\n",
    "#Sklearn version: 0.24.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris: pd.core.frame.DataFrame = pd.read_csv(\"Data/iris.data\", header=None)\n",
    "x_iris: np.array = iris.iloc[:, :-1].values\n",
    "y_iris: np.array = iris[[4]].apply(le.fit_transform).values\n",
    "y_iris = y_iris.reshape(y_iris.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine:pd.core.frame.DataFrame = pd.read_csv(\"Data/wine.data\", header=None)\n",
    "x_wine: np.array = wine.iloc[:, 1:].values\n",
    "y_wine: np.array = wine.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdbc: pd.core.frame.DataFrame = pd.read_csv(\"Data/wdbc.data\", header=None)  \n",
    "x_wdbc: np.array = wdbc.iloc[:, 2:].values\n",
    "y_wdbc: np.array = wdbc[[1]].apply(le.fit_transform).values\n",
    "y_wdbc = y_wdbc.reshape(y_wdbc.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone: pd.core.frame.DataFrame = pd.read_csv(\"Data/abalone.data\", header=None) \n",
    "x_abalone: np.array = abalone.iloc[:, 1:].values\n",
    "y_abalone: np.array = abalone[[0]].apply(le.fit_transform).values\n",
    "y_abalone = y_abalone.reshape(y_abalone.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. (20 puncte) Aplicati o metoda de missing value imputation, unde este cazul; documentati metoda folosita.\n",
    "*Resurse*: Pentru missing value imputation, puteti urmari [Imputation of missing values](https://scikit-learn.org/stable/modules/impute.html), [How to Handle Missing Data with Python](https://machinelearningmastery.com/handle-missing-data-python/), [fancyimpute](https://github.com/iskandr/fancyimpute), [missingpy](https://github.com/epsilon-machine/missingpy).\n",
    "\n",
    "*Cerinta*: In cazul in care folositi un pachet ce trebuie instalat (nu face parte din distributia standard anaconda), includeti intr-o celula o comanda de instalare corespunzatoare folosind semn de exclamare, de exemplu:\n",
    "```python\n",
    "!pip install missingpy\n",
    "```\n",
    "(sursa: [https://github.com/epsilon-machine/missingpy](https://github.com/epsilon-machine/missingpy)). La executia celulei in Jupyter Notebook se instaleaza pachetul, iar in celulele ulterioare importurile din noul pachet functioneaza. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_nans(data_set: np.array, percentage: int = 5) -> np.array:\n",
    "    \"\"\"\n",
    "    Adding NaN values in a dataset.\n",
    "    \n",
    "    Args:\n",
    "        data_set:the numpy.ndarray containing the dataset\n",
    "        percentage:the percentage(from dataset size) of Nans values to be added in the dataset\n",
    "        \n",
    "    Returns:\n",
    "        the modified dataset\n",
    "    \"\"\"\n",
    "    result_set: np.array = data_set.copy()\n",
    "    choice: np.array = np.random.choice(result_set.size, int(percentage / 100 * result_set.size), replace=False)\n",
    "    rows, cols = np.unravel_index(choice, result_set.shape)   \n",
    "    result_set[rows, cols] = np.nan\n",
    "    return result_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_iris = random_nans(x_iris)\n",
    "x_wine = random_nans(x_wine)\n",
    "x_wdbc = random_nans(x_wdbc)\n",
    "x_abalone = random_nans(x_abalone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer(missing_values = np.nan, strategy=\"most_frequent\")\n",
    "x_iris = imp.fit_transform(x_iris)\n",
    "x_wine = imp.fit_transform(x_wine)\n",
    "x_wdbc = imp.fit_transform(x_wdbc)\n",
    "x_abalone = imp.fit_transform(x_abalone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. (numar de modele * numar de seturi de date \\* 1 punct = 20 de puncte) Pentru fiecare set de date aplicati 5 modele de clasificare din scikit learn. Pentru fiecare raportati: acuratete, precision, recall, scorul F1 - a se vedea [sklearn.metrics](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics), [Precision and recall](https://en.wikipedia.org/wiki/Precision_and_recall) - folosind 5 fold cross validation. Raportati mediile rezultatelor atat pentru fold-urile de antrenare, cat si pentru cele de testare. Rularile se vor face cu valori fixate ale hiperparametrilor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  x_iris_train, x_iris_test, y_iris_train, y_iris_test =train_test_split(\n",
    "#     x_iris, y_iris, test_size=1/3, random_state=20, shuffle=True)\n",
    "\n",
    "# x_wine_train, x_wine_test, y_wine_train, y_wine_test = train_test_split(\n",
    "#     x_wine, y_wine, test_size=1/3, random_state=20, shuffle=True)\n",
    "\n",
    "# x_wdbc_train, x_wdbc_test, y_wdbc_train, y_wdbc_test = train_test_split(\n",
    "#     x_wdbc, y_wdbc, test_size=1/3, random_state=20, shuffle=True)\n",
    "\n",
    "# x_abalone_train, x_abalone_test, y_abalone_train, y_abalone_test = train_test_split(\n",
    "#     x_abalone, y_abalone, test_size=1/3, random_state=20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def KNeighbours(x, y, n_neighbors=5):\n",
    "#     model_5 = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "#     model_5.fit(x, y)\n",
    "#     y_pred = model_5.predict(x)\n",
    "#     return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'KNeighbours: {round(accuracy_score(y_iris_train, KNeighbours(x_iris_train, y_iris_train)) * 100, 2)}% accuracy for iris_train')\n",
    "# print(f'KNeighbours: {round(accuracy_score(y_wine_train, KNeighbours(x_wine_train, y_wine_train)) * 100, 2)}% accuracy for wine_train')\n",
    "# print(f'KNeighbours: {round(accuracy_score(y_wdbc_train, KNeighbours(x_wdbc_train, y_wdbc_train)) * 100, 2)}% accuracy for wdbc_train')\n",
    "# print(f'KNeighbours: {round(accuracy_score(y_abalone_train, KNeighbours(x_abalone_train, y_abalone_train)) * 100, 2)}% accuracy for abalone_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'KNeighbours: {round(accuracy_score(y_iris_test, KNeighbours(x_iris_test, y_iris_test)) * 100, 2)} % accuracy for iris_test')\n",
    "# print(f'KNeighbours: {round(accuracy_score(y_wine_test, KNeighbours(x_wine_test, y_wine_test)) * 100, 2)} % accuracy for wine_test')\n",
    "# print(f'KNeighbours: {round(accuracy_score(y_wdbc_test, KNeighbours(x_wdbc_test, y_wdbc_test)) * 100, 2)} % accuracy for wdbc_test')\n",
    "# print(f'KNeighbours: {round(accuracy_score(y_abalone_test, KNeighbours(x_abalone_test, y_abalone_test)) * 100, 2)} % accuracy for abalone_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'KNeighbours: {precision_score(y_iris_train, KNeighbours(x_iris_train, y_iris_train, 5), average=None) * 100} precision for iris_train')\n",
    "# print(f'KNeighbours: {precision_score(y_wine_train, KNeighbours(x_wine_train, y_wine_train, 5), average=None) * 100} precision for wine_train')\n",
    "# print(f'KNeighbours: {precision_score(y_wdbc_train, KNeighbours(x_wdbc_train, y_wdbc_train, 5), average=None) * 100} precision for wdbc_train')\n",
    "# print(f'KNeighbours: {precision_score(y_abalone_train, KNeighbours(x_abalone_train, y_abalone_train, 5), average=None) * 100} precision for abalone_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def LRegression(x,y):\n",
    "#     logreg = LogisticRegression(solver='sag', multi_class='multinomial', max_iter=10000)\n",
    "#     logreg.fit(x, y)\n",
    "#     y_pred = logreg.predict(X_test)\n",
    "#     return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metrics_classifier(clf,x,y):\n",
    "    scoring=['recall_macro','precision_macro','accuracy','f1_macro']\n",
    "    scores = cross_validate(clf,x, y, cv=5,scoring=scoring,return_train_score=True)\n",
    "    df = pd.DataFrame(data={'train_accuracy': scores['train_accuracy'],\n",
    "                            'train_recall': scores['train_recall_macro'],\n",
    "                            'train_precision': scores['train_precision_macro'],\n",
    "                            'train_f1': scores['train_f1_macro'],\n",
    "                            'test_accuracy': scores['test_accuracy'],\n",
    "                            'test_recall': scores['test_recall_macro'],\n",
    "                            'test_precision': scores['test_precision_macro'],\n",
    "                            'test_f1': scores['test_f1_macro']\n",
    "                           })\n",
    "    df.loc['mean'] = df.mean()\n",
    "    with pd.option_context('expand_frame_repr', False):\n",
    "        print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for KNeighborsClassifier:\n",
      "\n",
      "Iris_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.991667      0.991667         0.991870  0.991665       0.966667     0.966667        0.969697  0.966583\n",
      "1           0.983333      0.983333         0.983333  0.983333       1.000000     1.000000        1.000000  1.000000\n",
      "2           0.966667      0.966667         0.967022  0.966443       0.900000     0.900000        0.914141  0.895000\n",
      "3           0.991667      0.991667         0.991870  0.991665       0.966667     0.966667        0.969697  0.966583\n",
      "4           0.983333      0.983333         0.983333  0.983333       1.000000     1.000000        1.000000  1.000000\n",
      "mean        0.983333      0.983333         0.983486  0.983288       0.966667     0.966667        0.970707  0.965633\n",
      "\n",
      "Wine_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.781690      0.773236         0.775020  0.774075       0.777778     0.776984        0.774087  0.774691\n",
      "1           0.788732      0.778649         0.777897  0.777985       0.694444     0.696032        0.695833  0.684127\n",
      "2           0.816901      0.812057         0.812478  0.811957       0.611111     0.607143        0.623155  0.610925\n",
      "3           0.804196      0.799102         0.799735  0.798941       0.685714     0.669312        0.722222  0.681019\n",
      "4           0.734266      0.722527         0.718080  0.716221       0.742857     0.711111        0.695238  0.693333\n",
      "mean        0.785157      0.777114         0.776642  0.775836       0.702381     0.692116        0.702107  0.688819\n",
      "\n",
      "Wdbc_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.951648      0.944594         0.951488  0.947836       0.868421     0.834753        0.889482  0.850980\n",
      "1           0.938462      0.928053         0.939604  0.933262       0.929825     0.916148        0.934359  0.923822\n",
      "2           0.940659      0.933643         0.939080  0.936223       0.929825     0.914683        0.934211  0.922973\n",
      "3           0.938462      0.930702         0.937254  0.933778       0.921053     0.912698        0.916973  0.914749\n",
      "4           0.942982      0.934266         0.943311  0.938430       0.920354     0.917170        0.913289  0.915144\n",
      "mean        0.942443      0.934251         0.942147  0.937906       0.913895     0.899090        0.917663  0.905534\n",
      "\n",
      "Abalone_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.690811      0.695409         0.689965  0.690195       0.494019     0.504236        0.484384  0.481379\n",
      "1           0.661179      0.666776         0.663200  0.661042       0.516746     0.521096        0.508720  0.513932\n",
      "2           0.689408      0.693756         0.687977  0.688279       0.508982     0.514893        0.508561  0.509625\n",
      "3           0.670557      0.675839         0.671081  0.670255       0.519760     0.522177        0.520514  0.521079\n",
      "4           0.681628      0.686092         0.682096  0.681641       0.529341     0.534676        0.529304  0.531244\n",
      "mean        0.678716      0.683574         0.678864  0.678282       0.513770     0.519416        0.510297  0.511452\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics for KNeighborsClassifier:\")\n",
    "print(\"\\nIris_Dataset:\")\n",
    "show_metrics_classifier(KNeighborsClassifier(n_neighbors=5),x_iris,y_iris) \n",
    "print(\"\\nWine_Dataset:\")\n",
    "show_metrics_classifier(KNeighborsClassifier(n_neighbors=5),x_wine ,y_wine )\n",
    "print(\"\\nWdbc_Dataset:\")\n",
    "show_metrics_classifier(KNeighborsClassifier(n_neighbors=5),x_wdbc ,y_wdbc )\n",
    "print(\"\\nAbalone_Dataset:\")\n",
    "show_metrics_classifier(KNeighborsClassifier(n_neighbors=5),x_abalone ,y_abalone )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for LogisticRegression:\n",
      "\n",
      "Iris_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.983333      0.983333         0.984127  0.983323       0.933333     0.933333        0.933333  0.933333\n",
      "1           0.966667      0.966667         0.967419  0.966646       1.000000     1.000000        1.000000  1.000000\n",
      "2           0.983333      0.983333         0.983333  0.983333       0.966667     0.966667        0.969697  0.966583\n",
      "3           0.983333      0.983333         0.984127  0.983323       0.966667     0.966667        0.969697  0.966583\n",
      "4           0.975000      0.975000         0.975193  0.974996       1.000000     1.000000        1.000000  1.000000\n",
      "mean        0.978333      0.978333         0.978840  0.978324       0.973333     0.973333        0.974545  0.973300\n",
      "\n",
      "Wine_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.936620      0.929016         0.950926  0.937240       0.861111     0.857937        0.868519  0.862119\n",
      "1           0.915493      0.907304         0.931041  0.916034       0.888889     0.885714        0.889703  0.884690\n",
      "2           0.915493      0.908548         0.927787  0.915882       0.916667     0.911111        0.941176  0.919895\n",
      "3           0.902098      0.898412         0.913420  0.904359       0.914286     0.898148        0.941176  0.911583\n",
      "4           0.916084      0.914225         0.923045  0.917925       0.971429     0.962963        0.979167  0.969639\n",
      "mean        0.917157      0.911501         0.929244  0.918288       0.910476     0.903175        0.923948  0.909585\n",
      "\n",
      "Wdbc_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.909890      0.893222         0.912672  0.901332       0.850877     0.816083        0.867759  0.831111\n",
      "1           0.896703      0.875471         0.902270  0.885901       0.921053     0.904520        0.927632  0.913832\n",
      "2           0.901099      0.879515         0.909066  0.890756       0.894737     0.876984        0.894737  0.884459\n",
      "3           0.903297      0.882456         0.910737  0.893343       0.938596     0.921627        0.947525  0.932206\n",
      "4           0.916667      0.897779         0.924272  0.908265       0.911504     0.900402        0.908904  0.904302\n",
      "mean        0.905531      0.885689         0.911803  0.895919       0.903354     0.883923        0.909311  0.893182\n",
      "\n",
      "Abalone_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.560611      0.554694         0.557561  0.534378       0.502392     0.508769        0.490890  0.481495\n",
      "1           0.539359      0.535311         0.534122  0.517379       0.588517     0.577477        0.602713  0.547410\n",
      "2           0.557750      0.553630         0.555312  0.537520       0.511377     0.509877        0.503752  0.499890\n",
      "3           0.541592      0.538679         0.536046  0.524156       0.574850     0.568775        0.573229  0.554846\n",
      "4           0.546679      0.542370         0.540531  0.524509       0.532934     0.526654        0.531804  0.507718\n",
      "mean        0.549198      0.544937         0.544715  0.527588       0.542014     0.538310        0.540478  0.518272\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics for LogisticRegression:\")\n",
    "print(\"\\nIris_Dataset:\")\n",
    "show_metrics_classifier(LogisticRegression(solver='sag', multi_class='multinomial', max_iter=10000),x_iris,y_iris) \n",
    "print(\"\\nWine_Dataset:\")\n",
    "show_metrics_classifier(LogisticRegression(solver='sag', multi_class='multinomial', max_iter=10000),x_wine ,y_wine )\n",
    "print(\"\\nWdbc_Dataset:\")\n",
    "show_metrics_classifier(LogisticRegression(solver='sag', multi_class='multinomial', max_iter=10000),x_wdbc ,y_wdbc )\n",
    "print(\"\\nAbalone_Dataset:\")\n",
    "show_metrics_classifier(LogisticRegression(solver='sag', multi_class='multinomial', max_iter=10000),x_abalone ,y_abalone )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for GaussianNB:\n",
      "\n",
      "Iris_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.958333      0.958333         0.958516  0.958327       0.900000     0.900000        0.902357  0.899749\n",
      "1           0.958333      0.958333         0.958516  0.958327       0.966667     0.966667        0.969697  0.966583\n",
      "2           0.958333      0.958333         0.959983  0.958275       0.966667     0.966667        0.969697  0.966583\n",
      "3           0.966667      0.966667         0.966667  0.966667       0.933333     0.933333        0.944444  0.932660\n",
      "4           0.950000      0.950000         0.950710  0.949969       1.000000     1.000000        1.000000  1.000000\n",
      "mean        0.958333      0.958333         0.958878  0.958313       0.953333     0.953333        0.957239  0.953115\n",
      "\n",
      "Wine_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.985915      0.987060         0.985605  0.986239       0.888889     0.904762        0.896825  0.888500\n",
      "1           0.971831      0.975364         0.970181  0.972456       0.916667     0.919048        0.915385  0.916296\n",
      "2           0.971831      0.976608         0.968665  0.971712       0.972222     0.972222        0.977778  0.974013\n",
      "3           0.951049      0.953877         0.950506  0.951932       0.914286     0.916667        0.941176  0.920123\n",
      "4           0.951049      0.957341         0.949655  0.952242       1.000000     1.000000        1.000000  1.000000\n",
      "mean        0.966335      0.970050         0.964922  0.966916       0.938413     0.942540        0.946233  0.939787\n",
      "\n",
      "Wdbc_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.929670      0.918639         0.929936  0.923728       0.912281     0.906649        0.906649  0.906649\n",
      "1           0.940659      0.932222         0.940126  0.935898       0.903509     0.881264        0.914530  0.893467\n",
      "2           0.929670      0.917750         0.931317  0.923728       0.947368     0.938492        0.947973  0.942867\n",
      "3           0.929670      0.920124         0.928833  0.924126       0.947368     0.938492        0.947973  0.942867\n",
      "4           0.936404      0.930214         0.933396  0.931756       0.955752     0.955064        0.950831  0.952858\n",
      "mean        0.933215      0.923790         0.932722  0.927847       0.933256     0.923992        0.933591  0.927741\n",
      "\n",
      "Abalone_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.545346      0.554054         0.532172  0.536964       0.497608     0.510680        0.487688  0.463475\n",
      "1           0.514217      0.532975         0.497481  0.477540       0.545455     0.563352        0.535519  0.524054\n",
      "2           0.532914      0.553430         0.526350  0.489449       0.485030     0.504117        0.476520  0.445802\n",
      "3           0.514961      0.533160         0.493567  0.481285       0.544910     0.563071        0.533268  0.520258\n",
      "4           0.519150      0.534771         0.497808  0.495921       0.532934     0.548631        0.515941  0.514164\n",
      "mean        0.525318      0.541678         0.509476  0.496232       0.521187     0.537970        0.509787  0.493550\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics for GaussianNB:\")\n",
    "print(\"\\nIris_Dataset:\")\n",
    "show_metrics_classifier(GaussianNB(),x_iris,y_iris) \n",
    "print(\"\\nWine_Dataset:\")\n",
    "show_metrics_classifier(GaussianNB(),x_wine ,y_wine )\n",
    "print(\"\\nWdbc_Dataset:\")\n",
    "show_metrics_classifier(GaussianNB(),x_wdbc ,y_wdbc )\n",
    "print(\"\\nAbalone_Dataset:\")\n",
    "show_metrics_classifier(GaussianNB(),x_abalone ,y_abalone )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for RandomForestClassifier:\n",
      "\n",
      " Iris_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.991667      0.991667         0.991870  0.991665       0.966667     0.966667        0.969697  0.966583\n",
      "1           0.991667      0.991667         0.991870  0.991665       0.966667     0.966667        0.969697  0.966583\n",
      "2           1.000000      1.000000         1.000000  1.000000       0.933333     0.933333        0.939394  0.931217\n",
      "3           0.991667      0.991667         0.991870  0.991665       0.966667     0.966667        0.969697  0.966583\n",
      "4           0.983333      0.983333         0.984127  0.983323       1.000000     1.000000        1.000000  1.000000\n",
      "mean        0.991667      0.991667         0.991947  0.991664       0.966667     0.966667        0.969697  0.966193\n",
      "\n",
      " Wine_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.992958      0.992908         0.994253  0.993517       0.833333     0.857143        0.863248  0.829091\n",
      "1           0.992958      0.992908         0.994253  0.993517       0.916667     0.919048        0.915385  0.916296\n",
      "2           0.992958      0.992908         0.994253  0.993517       0.916667     0.911111        0.941176  0.919895\n",
      "3           0.986014      0.988304         0.986395  0.987103       1.000000     1.000000        1.000000  1.000000\n",
      "4           1.000000      1.000000         1.000000  1.000000       0.942857     0.947475        0.947475  0.947475\n",
      "mean        0.992977      0.993405         0.993831  0.993531       0.921905     0.926955        0.933457  0.922551\n",
      "\n",
      " Wdbc_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.989011      0.985207         0.991409  0.988160       0.912281     0.897478        0.914872  0.904778\n",
      "1           0.993407      0.991124         0.994810  0.992914       0.929825     0.911562        0.941032  0.922973\n",
      "2           0.984615      0.980599         0.986625  0.983465       0.973684     0.969246        0.974106  0.971583\n",
      "3           0.978022      0.972962         0.980157  0.976349       0.929825     0.919643        0.928716  0.923822\n",
      "4           0.982456      0.978856         0.983631  0.981151       0.955752     0.955064        0.950831  0.952858\n",
      "mean        0.985502      0.981750         0.987326  0.984408       0.940273     0.930599        0.941911  0.935203\n",
      "\n",
      " Abalone_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.589943      0.582951         0.599672  0.558151       0.502392     0.500425        0.495237  0.449949\n",
      "1           0.584256      0.585876         0.580172  0.578391       0.568182     0.565232        0.564232  0.558679\n",
      "2           0.596948      0.597743         0.592789  0.589789       0.518563     0.520545        0.515284  0.514190\n",
      "3           0.584979      0.582367         0.587846  0.568260       0.573653     0.567540        0.563247  0.548669\n",
      "4           0.587672      0.583532         0.592991  0.571713       0.529341     0.524150        0.527717  0.508980\n",
      "mean        0.588760      0.586494         0.590694  0.573261       0.538426     0.535578        0.533143  0.516093\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics for RandomForestClassifier:\")\n",
    "print(\"\\n Iris_Dataset:\")\n",
    "show_metrics_classifier(RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1), x_iris, y_iris) \n",
    "print(\"\\n Wine_Dataset:\")\n",
    "show_metrics_classifier(RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1), x_wine ,y_wine )\n",
    "print(\"\\n Wdbc_Dataset:\")\n",
    "show_metrics_classifier(RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1), x_wdbc ,y_wdbc )\n",
    "print(\"\\n Abalone_Dataset:\")\n",
    "show_metrics_classifier(RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1), x_abalone ,y_abalone )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for DecisionTreeClassifier:\n",
      "\n",
      "Iris_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.991667      0.991667         0.991870  0.991665       0.966667     0.966667        0.969697  0.966583\n",
      "1           1.000000      1.000000         1.000000  1.000000       0.933333     0.933333        0.944444  0.934609\n",
      "2           1.000000      1.000000         1.000000  1.000000       0.933333     0.933333        0.933333  0.933333\n",
      "3           1.000000      1.000000         1.000000  1.000000       0.966667     0.966667        0.969697  0.966583\n",
      "4           1.000000      1.000000         1.000000  1.000000       1.000000     1.000000        1.000000  1.000000\n",
      "mean        0.998333      0.998333         0.998374  0.998333       0.960000     0.960000        0.963434  0.960222\n",
      "\n",
      "Wine_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0                1.0           1.0              1.0       1.0       0.777778     0.800000        0.791667  0.769814\n",
      "1                1.0           1.0              1.0       1.0       0.833333     0.828571        0.840385  0.827160\n",
      "2                1.0           1.0              1.0       1.0       0.805556     0.811905        0.817172  0.811315\n",
      "3                1.0           1.0              1.0       1.0       0.885714     0.870370        0.925926  0.886364\n",
      "4                1.0           1.0              1.0       1.0       0.971429     0.962963        0.979167  0.969639\n",
      "mean             1.0           1.0              1.0       1.0       0.854762     0.854762        0.870863  0.852858\n",
      "\n",
      "Wdbc_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.995604      0.994083         0.996528  0.995282       0.894737     0.887979        0.887979  0.887979\n",
      "1           0.995604      0.994083         0.996528  0.995282       0.956140     0.946446        0.960473  0.952638\n",
      "2           0.986813      0.982353         0.989691  0.985810       0.947368     0.938492        0.947973  0.942867\n",
      "3           0.989011      0.985294         0.991379  0.988189       0.938596     0.941468        0.929952  0.934947\n",
      "4           0.986842      0.983546         0.988367  0.985863       0.955752     0.959926        0.948203  0.953279\n",
      "mean        0.990775      0.987872         0.992499  0.990085       0.938519     0.934862        0.934916  0.934342\n",
      "\n",
      "Abalone_Dataset:\n",
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0           0.594732      0.586139         0.611790  0.572756       0.507177     0.507724        0.489464  0.489790\n",
      "1           0.578270      0.580849         0.571809  0.573398       0.568182     0.567559        0.564465  0.561166\n",
      "2           0.584081      0.581479         0.577554  0.567186       0.529341     0.527510        0.526095  0.521036\n",
      "3           0.581987      0.575370         0.598695  0.570971       0.568862     0.562889        0.583774  0.563255\n",
      "4           0.588270      0.592701         0.585999  0.588638       0.532934     0.537371        0.538176  0.537516\n",
      "mean        0.585468      0.583307         0.589169  0.574590       0.541299     0.540611        0.540395  0.534553\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics for DecisionTreeClassifier:\")\n",
    "print(\"\\nIris_Dataset:\")\n",
    "show_metrics_classifier(DecisionTreeClassifier(max_depth=5),x_iris,y_iris) \n",
    "print(\"\\nWine_Dataset:\")\n",
    "show_metrics_classifier(DecisionTreeClassifier(max_depth=5),x_wine ,y_wine )\n",
    "print(\"\\nWdbc_Dataset:\")\n",
    "show_metrics_classifier(DecisionTreeClassifier(max_depth=5),x_wdbc ,y_wdbc )\n",
    "print(\"\\nAbalone_Dataset:\")\n",
    "show_metrics_classifier(DecisionTreeClassifier(max_depth=5),x_abalone ,y_abalone )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "def show_metrics_classifier_2(clf, parameter_grid, x, y):\n",
    "    show_metrics_classifier(GridSearchCV(estimator = clf, \n",
    "        param_grid=parameter_grid, cv=4, return_train_score=True),x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train_accuracy  train_recall  train_precision  train_f1  test_accuracy  test_recall  test_precision   test_f1\n",
      "0              1.000         1.000         1.000000  1.000000       0.966667     0.966667        0.969697  0.966583\n",
      "1              1.000         1.000         1.000000  1.000000       0.966667     0.966667        0.969697  0.966583\n",
      "2              1.000         1.000         1.000000  1.000000       1.000000     1.000000        1.000000  1.000000\n",
      "3              1.000         1.000         1.000000  1.000000       0.966667     0.966667        0.969697  0.966583\n",
      "4              0.975         0.975         0.975193  0.974996       1.000000     1.000000        1.000000  1.000000\n",
      "mean           0.995         0.995         0.995039  0.994999       0.980000     0.980000        0.981818  0.979950\n"
     ]
    }
   ],
   "source": [
    "parameter_grid = {'n_neighbors': list(range(1, 10)), 'p': [1, 2, 3, 10]}\n",
    "show_metrics_classifier_2(KNeighborsClassifier(n_neighbors=5),parameter_grid,x_iris,y_iris) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
