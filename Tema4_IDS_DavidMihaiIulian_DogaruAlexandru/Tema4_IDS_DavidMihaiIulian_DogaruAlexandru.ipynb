{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modele de clasificare\n",
    "Folositi 4 seturi de date pentru probleme de clasificare, plecand de la repository-urile specificate in Cursul 6. Cel putin un set de date sa fie cu valori lipsa; pentru un alt set de date care are initial toate valorile, introduceti dvs. in mod artificial valori lipsa, suprascriind un anumit procent din valorile initiale (ex. p=5%, p parametru) cu numpy.nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 1.20.1\n",
      "Pandas version: 1.2.3\n",
      "Sklearn version: 0.24.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(f'NumPy version: {np.__version__}')\n",
    "import pandas as pd\n",
    "print(f'Pandas version: {pd.__version__}')\n",
    "import sklearn as sk\n",
    "print(f'Sklearn version: {sk.__version__}')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#NumPy version: 1.20.1\n",
    "#Pandas version: 1.2.3\n",
    "#Sklearn version: 0.24.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris: pd.core.frame.DataFrame=pd.read_csv(\"Data/iris.data\",header=None)\n",
    "x_iris:np.array = iris.iloc[:, :-1].values\n",
    "y_iris:np.array = iris[[4]].apply(le.fit_transform).values\n",
    "y_iris=y_iris.reshape(y_iris.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine:pd.core.frame.DataFrame=pd.read_csv(\"Data/wine.data\",header=None)\n",
    "x_wine:np.array = wine.iloc[:,1:].values\n",
    "y_wine:np.array = wine.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdbc:pd.core.frame.DataFrame=pd.read_csv(\"Data/wdbc.data\",header=None)  \n",
    "x_wdbc:np.array = wdbc.iloc[:, 2:].values\n",
    "y_wdbc:np.array = wdbc[[1]].apply(le.fit_transform).values\n",
    "y_wdbc=y_wdbc.reshape(y_wdbc.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone:pd.core.frame.DataFrame=pd.read_csv(\"Data/abalone.data\",header=None) \n",
    "x_abalone:np.array = abalone.iloc[:, 1:].values\n",
    "y_abalone:np.array = abalone[[0]].apply(le.fit_transform).values\n",
    "y_abalone=y_abalone.reshape(y_abalone.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. (20 puncte) Aplicati o metoda de missing value imputation, unde este cazul; documentati metoda folosita.\n",
    "*Resurse*: Pentru missing value imputation, puteti urmari [Imputation of missing values](https://scikit-learn.org/stable/modules/impute.html), [How to Handle Missing Data with Python](https://machinelearningmastery.com/handle-missing-data-python/), [fancyimpute](https://github.com/iskandr/fancyimpute), [missingpy](https://github.com/epsilon-machine/missingpy).\n",
    "\n",
    "*Cerinta*: In cazul in care folositi un pachet ce trebuie instalat (nu face parte din distributia standard anaconda), includeti intr-o celula o comanda de instalare corespunzatoare folosind semn de exclamare, de exemplu:\n",
    "```python\n",
    "!pip install missingpy\n",
    "```\n",
    "(sursa: [https://github.com/epsilon-machine/missingpy](https://github.com/epsilon-machine/missingpy)). La executia celulei in Jupyter Notebook se instaleaza pachetul, iar in celulele ulterioare importurile din noul pachet functioneaza. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_Nans(data_set:np.array,percentage:int = 5)->np.array:\n",
    "    \"\"\"\n",
    "    Adding NaN values in a dataset.\n",
    "    Args:\n",
    "        data_set:the numpy.ndarray containing the dataset\n",
    "        percentage:the percentage(from dataset size) of Nans values to be added in the dataset\n",
    "    Returns:the modified dataset\n",
    "    \"\"\"\n",
    "    result_set:np.array=data_set.copy()\n",
    "    choice:np.array = np.random.choice(result_set.size, int(percentage / 100 * result_set.size), replace=False)\n",
    "    rows,cols= np.unravel_index(choice, result_set.shape)   \n",
    "    result_set[rows, cols] = np.nan\n",
    "    return result_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_iris=Random_Nans(x_iris)\n",
    "x_wine=Random_Nans(x_wine)\n",
    "x_wdbc=Random_Nans(x_wdbc)\n",
    "x_abalone=Random_Nans(x_abalone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")\n",
    "x_iris=imp.fit_transform(x_iris)\n",
    "x_wine=imp.fit_transform(x_wine)\n",
    "x_wdbc=imp.fit_transform(x_wdbc)\n",
    "x_abalone=imp.fit_transform(x_abalone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. (numar de modele * numar de seturi de date \\* 1 punct = 20 de puncte) Pentru fiecare set de date aplicati 5 modele de clasificare din scikit learn. Pentru fiecare raportati: acuratete, precision, recall, scorul F1 - a se vedea [sklearn.metrics](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics), [Precision and recall](https://en.wikipedia.org/wiki/Precision_and_recall) - folosind 5 fold cross validation. Raportati mediile rezultatelor atat pentru fold-urile de antrenare, cat si pentru cele de testare. Rularile se vor face cu valori fixate ale hiperparametrilor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_iris_train, x_iris_test, y_iris_train, y_iris_test =train_test_split(\n",
    "    x_iris, y_iris, test_size=1/3, random_state=20,shuffle=True)\n",
    "\n",
    "x_wine_train, x_wine_test, y_wine_train, y_wine_test = train_test_split(\n",
    "    x_wine, y_wine, test_size=1/3, random_state=20,shuffle=True)\n",
    "\n",
    "x_wdbc_train, x_wdbc_test, y_wdbc_train, y_wdbc_test = train_test_split(\n",
    "    x_wdbc, y_wdbc, test_size=1/3, random_state=20,shuffle=True)\n",
    "\n",
    "x_abalone_train, x_abalone_test, y_abalone_train, y_abalone_test = train_test_split(\n",
    "    x_abalone, y_abalone, test_size=1/3, random_state=20,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNeighbours(x,y,n_neighbors=5):\n",
    "    model_5 = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    model_5.fit(x, y)\n",
    "    y_pred = model_5.predict(x)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighbours:96.0% accuracy for iris_train\n",
      "KNeighbours:82.2% accuracy for wine_train\n",
      "KNeighbours:94.72% accuracy for wdbc_train\n",
      "KNeighbours:67.21% accuracy for abalone_train\n"
     ]
    }
   ],
   "source": [
    "print(f'KNeighbours:{round(accuracy_score(y_iris_train,KNeighbours(x_iris_train,y_iris_train)) * 100, 2)}% accuracy for iris_train')\n",
    "print(f'KNeighbours:{round(accuracy_score(y_wine_train,KNeighbours(x_wine_train,y_wine_train)) * 100,2)}% accuracy for wine_train')\n",
    "print(f'KNeighbours:{round(accuracy_score(y_wdbc_train,KNeighbours(x_wdbc_train,y_wdbc_train)) * 100,2)}% accuracy for wdbc_train')\n",
    "print(f'KNeighbours:{round(accuracy_score(y_abalone_train,KNeighbours(x_abalone_train,y_abalone_train)) * 100,2)}% accuracy for abalone_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighbours:92.0% accuracy for iris_test\n",
      "KNeighbours:70.0% accuracy for wine_test\n",
      "KNeighbours:93.16% accuracy for wdbc_test\n",
      "KNeighbours:64.97% accuracy for abalone_test\n"
     ]
    }
   ],
   "source": [
    "print(f'KNeighbours:{round(accuracy_score(y_iris_test,KNeighbours(x_iris_test,y_iris_test)) * 100, 2)}% accuracy for iris_test')\n",
    "print(f'KNeighbours:{round(accuracy_score(y_wine_test,KNeighbours(x_wine_test,y_wine_test)) * 100,2)}% accuracy for wine_test')\n",
    "print(f'KNeighbours:{round(accuracy_score(y_wdbc_test,KNeighbours(x_wdbc_test,y_wdbc_test)) * 100,2)}% accuracy for wdbc_test')\n",
    "print(f'KNeighbours:{round(accuracy_score(y_abalone_test,KNeighbours(x_abalone_test,y_abalone_test)) * 100,2)}% accuracy for abalone_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighbours:[ 91.66666667 100.          97.05882353] precision for iris_train\n",
      "KNeighbours:[85.10638298 78.26086957 84.        ] precision for wine_train\n",
      "KNeighbours:[94.69387755 94.7761194 ] precision for wdbc_train\n",
      "KNeighbours:[57.67590618 76.65975104 67.00680272] precision for abalone_train\n"
     ]
    }
   ],
   "source": [
    "print(f'KNeighbours:{precision_score(y_iris_train,KNeighbours(x_iris_train,y_iris_train,5),average=None) * 100} precision for iris_train')\n",
    "print(f'KNeighbours:{precision_score(y_wine_train,KNeighbours(x_wine_train,y_wine_train,5),average=None) * 100} precision for wine_train')\n",
    "print(f'KNeighbours:{precision_score(y_wdbc_train,KNeighbours(x_wdbc_train,y_wdbc_train,5),average=None) * 100} precision for wdbc_train')\n",
    "print(f'KNeighbours:{precision_score(y_abalone_train,KNeighbours(x_abalone_train,y_abalone_train,5),average=None) * 100} precision for abalone_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LRegression(x,y):\n",
    "    logreg = LogisticRegression(solver='sag', multi_class='multinomial', max_iter=10000)\n",
    "    logreg.fit(x, y)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
