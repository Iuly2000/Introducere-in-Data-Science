{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folositi urmatoarele seturi de date:\n",
    "1. [CPU Computer Hardware](https://archive.ics.uci.edu/ml/datasets/Computer+Hardware); excludeti din dataset coloanele: vendor name, model name, estimated relative performance; se va estima coloana \"published relative performance\".\n",
    "1. [Boston Housing](http://archive.ics.uci.edu/ml/machine-learning-databases/housing/)\n",
    "1. [Wisconsin Breast Cancer](http://www.dcc.fc.up.pt/~ltorgo/Regression/DataSets.html); cautati in panelul din stanga Wisconsin Breast Cancer si urmati pasii din \"My personal Notes\"\n",
    "1. [Communities and Crime](http://archive.ics.uci.edu/ml/datasets/communities+and+crime); stergeti primele 5 dimensiuni si trasaturile cu missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 1.20.1\n",
      "Pandas version: 1.2.3\n",
      "Sklearn version: 0.24.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(f'NumPy version: {np.__version__}')\n",
    "\n",
    "import pandas as pd\n",
    "print(f'Pandas version: {pd.__version__}')\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "print(f'Sklearn version: {sk.__version__}')\n",
    "\n",
    "#NumPy version: 1.19.2\n",
    "#Pandas version: 1.2.3\n",
    "#Sklearn version: 0.24.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine: pd.core.frame.DataFrame = pd.read_csv(\"Data/machine.data\", header=None)\n",
    "x_machine: np.ndarray = machine.iloc[:, 2:8].values\n",
    "y_machine: np.ndarray = machine.iloc[:, 8].values\n",
    "y_machine = y_machine.reshape(y_machine.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "housing: pd.core.frame.DataFrame = pd.read_csv(\"Data/housing.data\", delim_whitespace=True, header=None)\n",
    "x_housing: np.ndarray = housing.iloc[:, :-1].values\n",
    "y_housing: np.ndarray = housing.iloc[:, -1].values\n",
    "y_housing = y_housing.reshape(y_housing.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "r_wpbc: pd.core.frame.DataFrame = pd.read_csv(\"Data/r_wpbc.data\", header=None)\n",
    "x_r_wpbc: np.ndarray = r_wpbc.iloc[:, 1:].values\n",
    "y_r_wpbc: np.ndarray = r_wpbc.iloc[:, 1].values\n",
    "y_r_wpbc = y_r_wpbc.reshape(y_r_wpbc.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "communities: pd.core.frame.DataFrame = pd.read_csv(\"Data/communities.data\", header=None)\n",
    "communities = communities.replace('?', np.nan)    \n",
    "x_communities: np.ndarray = communities.iloc[:, 1:].drop([3], axis=1).values\n",
    "y_communities: np.ndarray = communities.iloc[:, 0].values\n",
    "y_communities = y_communities.reshape(y_communities.shape[0])\n",
    "\n",
    "imp:sk.impute._base.SimpleImputer = SimpleImputer(missing_values = np.nan, strategy=\"median\")\n",
    "x_communities = imp.fit_transform(x_communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metrics_regression(reg, parameters: dict, x: np.ndarray, y: np.ndarray) -> pd.core.frame.DataFrame:\n",
    "    \"\"\"\n",
    "    Shows the metrics('mean_absolute_error', 'mean_squared_error', 'median_absolute_error') of a regressor.\n",
    "    \n",
    "    Args:\n",
    "        reg: a regressor\n",
    "        parameters:a dictionary containning the hiperparameters\n",
    "        x: np.array containning the dataset information\n",
    "        y: np.array containning the classification of the data\n",
    "        \n",
    "    Returns:\n",
    "        a pandas dataframe with the metrics of a regressor\n",
    "    \"\"\"\n",
    "    gridsrc = GridSearchCV(estimator=reg, \n",
    "            param_grid=parameters, cv=3, n_jobs=-1, return_train_score=True)\n",
    "    randsrc = RandomizedSearchCV(estimator=reg,\n",
    "            param_distributions=parameters, n_iter=15, n_jobs=-1, return_train_score=True)\n",
    "    \n",
    "    scoring = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_median_absolute_error']\n",
    "    \n",
    "    scores1 = cross_validate(gridsrc, x, y, cv=5, scoring=scoring, return_train_score=True)\n",
    "    scores2 = cross_validate(randsrc, x, y, cv=5, scoring=scoring, return_train_score=True)\n",
    "    \n",
    "    df1 = pd.DataFrame(data={'train_neg_mean_absolute_error': scores1['train_neg_mean_absolute_error'],\n",
    "                            'train_neg_mean_squared_error': scores1['train_neg_mean_squared_error'],\n",
    "                            'train_neg_median_absolute_error': scores1['train_neg_median_absolute_error'],\n",
    "                            'test_neg_mean_absolute_error': scores1['test_neg_mean_absolute_error'],\n",
    "                            'test_neg_mean_squared_error': scores1['test_neg_mean_squared_error'],\n",
    "                            'test_neg_median_absolute_error':scores1['test_neg_median_absolute_error']\n",
    "                           })\n",
    "    df2 = pd.DataFrame(data={'train_neg_mean_absolute_error': scores2['train_neg_mean_absolute_error'],\n",
    "                            'train_neg_mean_squared_error': scores2['train_neg_mean_squared_error'],\n",
    "                            'train_neg_median_absolute_error': scores2['train_neg_median_absolute_error'],\n",
    "                            'test_neg_mean_absolute_error':scores2['test_neg_mean_absolute_error'],\n",
    "                            'test_neg_mean_squared_error':scores2['test_neg_mean_squared_error'],\n",
    "                            'test_neg_median_absolute_error': scores2['test_neg_median_absolute_error']\n",
    "                           })\n",
    "    \n",
    "    result = pd.DataFrame([df1.mean(), df2.mean()])\n",
    "    result.insert(0, 'Model_name', [reg, reg])\n",
    "    result.insert(1, 'Search_strategy', ['GridSearchCV', 'RandomizedSearchCV'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_SGDRegressor:dict = {\n",
    "    'max_iter':[10000],\n",
    "    'loss': ['squared_loss','huber','epsilon_insensitive','squared_epsilon_insensitive'],\n",
    "    'penalty' : ['l1', 'l2'],\n",
    "    'alpha' : [0.001, 0.01, 0.1, 1]\n",
    "}\n",
    "parameters_RandomForestRegressor:dict = {\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'n_jobs':[-1]\n",
    "}\n",
    "parameters_Lasso:dict = {\n",
    "    'alpha':[0.01,0.1,1],\n",
    "    'tol':[0.0001,0.001,0.01,0.1],\n",
    "    'selection':['cyclic','random']\n",
    "}\n",
    "parameters_MLPRegressor:dict = {\n",
    "    'max_iter':[10000],\n",
    "    'solver': ['sgd', 'adam','lbfgs'],\n",
    "    'alpha': [0.001, 0.01, 0.1, 1],\n",
    "    'tol':[0.0001, 0.001, 0.01]\n",
    "}\n",
    "\n",
    "parameters_Ridge:dict = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 1],\n",
    "    \"fit_intercept\": [True, False],\n",
    "    \"solver\": ['svd', 'lsqr', 'sag', 'saga']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_regression(name:str, x:np.ndarray, y:np.ndarray):\n",
    "    df1 = show_metrics_regression(SGDRegressor(), parameters_SGDRegressor, x, y)\n",
    "    df2 = show_metrics_regression(RandomForestRegressor(),parameters_RandomForestRegressor, x, y)\n",
    "    df3 = show_metrics_regression(Lasso(), parameters_Lasso, x, y)\n",
    "    df4 = show_metrics_regression(MLPRegressor(), parameters_MLPRegressor, x, y)\n",
    "    df5 = show_metrics_regression(Ridge(), parameters_Ridge, x, y)\n",
    "\n",
    "    df = pd.concat([df1, df2, df3, df4, df5], axis=0, ignore_index=True)\n",
    "    df.columns.name = name\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s)->list:    \n",
    "    \"\"\"\n",
    "    Highlight the maximum in a dataframe red for maximum and green for minimum.\n",
    "    \"\"\"\n",
    "    \n",
    "    max_val:float = s.max()\n",
    "    min_val:float = s.min()\n",
    "    return ['background-color: #ff6666' if v==max_val and type(v)\n",
    "            else 'background-color: #bdfcc2'if v==min_val else '' for v in s]\n",
    "\n",
    "def finishing(df:pd.core.frame.DataFrame)->pd.core.frame.DataFrame:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        df:a dataframe\n",
    "    \n",
    "    Returns:\n",
    "        a dataframe with positive numbers and highlights the maximum and minimum.\n",
    "    \"\"\"\n",
    "    df.iloc[:, 2:] = df.iloc[:, 2:].abs()\n",
    "    df.columns = ['Model_name', 'Search_strategy',\n",
    "                  'train_mean_absolute_error', 'train_mean_squared_error',\n",
    "                  'train_median_absolute_error', 'test_mean_absolute_error',\n",
    "                  'test_mean_squared_error', 'test_median_absolute_error']\n",
    "\n",
    "    return df.style.apply(highlight_max, subset=df.columns[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_machine:pd.core.frame.DataFrame = dataset_regression('Machine_Dataset',x_machine,y_machine)\n",
    "display(df_machine)\n",
    "display(finishing(df_machine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_housing:pd.core.frame.DataFrame = dataset_regression('Housing_Dataset',x_housing,y_housing)\n",
    "display(df_housing)\n",
    "display(finishing(df_housing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r_wpbc:pd.core.frame.DataFrame = dataset_regression('WPBC_Dataset',x_r_wpbc,y_r_wpbc)\n",
    "display(df_r_wpbc)\n",
    "display(finishing(df_r_wpbc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_communities:pd.core.frame.DataFrame = dataset_regression('Communities_Dataset',x_communities,y_communities)\n",
    "display(df_communities)\n",
    "display(finishing(df_communities))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
